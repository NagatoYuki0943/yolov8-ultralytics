

# 本地安装

```sh
git clone https://github.com/ultralytics/ultralytics
cd ultralytics
pip install -v -e .
# "-v" 指详细说明，或更多的输出
# "-e" 表示在可编辑模式下安装项目，因此对代码所做的任何本地修改都会生效，从而无需重新安装。
```

# [CLI](https://docs.ultralytics.com/usage/cli/)

The YOLO Command Line Interface (CLI) is the easiest way to get started training, validating, predicting and exporting YOLOv8 models.

The `yolo` command is used for all actions:

```sh
yolo TASK MODE ARGS
```

Where:

- `TASK` (optional) is one of `[detect, segment, classify]`. If it is not passed explicitly YOLOv8 will try to guess the `TASK` from the model type.
- `MODE` (required) is one of `[train, val, predict, export]`
- `ARGS` (optional) are any number of custom `arg=value` pairs like `imgsz=320` that override defaults. For a full list of available `ARGS` see the [Configuration](https://docs.ultralytics.com/usage/cfg/) page and `defaults.yaml` GitHub [source](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/yolo/cfg/default.yaml).

**Note:** Arguments MUST be passed as `arg=val` with an equals sign and a space between `arg=val` pairs

- `yolo predict model=yolov8n.pt imgsz=640 conf=0.25`  ✅
- `yolo predict model yolov8n.pt imgsz 640 conf 0.25`  ❌
- `yolo predict --model yolov8n.pt --imgsz 640 --conf 0.25`  ❌

## Overriding default arguments

Default arguments can be overridden by simply passing them as arguments in the CLI in `arg=value` pairs.

```sh
yolo detect train data=coco128.yaml model=yolov8n.pt epochs=10 lr0=0.01

yolo segment predict model=yolov8n-seg.pt source='https://youtu.be/Zgi9g1ksQHc' imgsz=320

yolo segment predict model=yolov8n-seg.pt source='https://youtu.be/Zgi9g1ksQHc' imgsz=320
```

## Overriding default config file

You can override the `default.yaml` config file entirely by passing a new file with the `cfg` arguments, i.e. `cfg=custom.yaml`.

To do this first create a copy of `default.yaml` in your current working dir with the `yolo copy-cfg` command.

This will create `default_copy.yaml`, which you can then pass as `cfg=default_copy.yaml` along with any additional args, like `imgsz=320` in this example:

```sh
yolo copy-cfg
yolo cfg=default_copy.yaml imgsz=320
```

默认配置文件位置在 `ultralytics/yolo/cfg/default.yaml`

```yaml
# Ultralytics YOLO 🚀, GPL-3.0 license
# Default training settings and hyperparameters for medium-augmentation COCO training

task: detect  # YOLO task, i.e. detect, segment, classify, pose
mode: train  # YOLO mode, i.e. train, val, predict, export, track, benchmark

# Train settings -------------------------------------------------------------------------------------------------------
model:  # path to model file, i.e. yolov8n.pt, yolov8n.yaml
data:  # path to data file, i.e. coco128.yaml
epochs: 100  # number of epochs to train for
patience: 50  # epochs to wait for no observable improvement for early stopping of training
batch: 16  # number of images per batch (-1 for AutoBatch)
imgsz: 640  # size of input images as integer or w,h
save: True  # save train checkpoints and predict results
save_period: -1 # Save checkpoint every x epochs (disabled if < 1)
cache: False  # True/ram, disk or False. Use cache for data loading
device:  # device to run on, i.e. cuda device=0 or device=0,1,2,3 or device=cpu
workers: 8  # number of worker threads for data loading (per RANK if DDP)
project:  # project name
name:  # experiment name, results saved to 'project/name' directory
exist_ok: False  # whether to overwrite existing experiment
pretrained: False  # whether to use a pretrained model
optimizer: SGD  # optimizer to use, choices=['SGD', 'Adam', 'AdamW', 'RMSProp']
verbose: True  # whether to print verbose output
seed: 0  # random seed for reproducibility
deterministic: True  # whether to enable deterministic mode
single_cls: False  # train multi-class data as single-class
image_weights: False  # use weighted image selection for training
rect: False  # support rectangular training if mode='train', support rectangular evaluation if mode='val'
cos_lr: False  # use cosine learning rate scheduler
close_mosaic: 10  # disable mosaic augmentation for final 10 epochs
resume: False  # resume training from last checkpoint
amp: True  # Automatic Mixed Precision (AMP) training, choices=[True, False], True runs AMP check
# Segmentation
overlap_mask: True  # masks should overlap during training (segment train only)
mask_ratio: 4  # mask downsample ratio (segment train only)
# Classification
dropout: 0.0  # use dropout regularization (classify train only)

# Val/Test settings ----------------------------------------------------------------------------------------------------
val: True  # validate/test during training
split: val  # dataset split to use for validation, i.e. 'val', 'test' or 'train'
save_json: False  # save results to JSON file
save_hybrid: False  # save hybrid version of labels (labels + additional predictions)
conf:  # object confidence threshold for detection (default 0.25 predict, 0.001 val)
iou: 0.7  # intersection over union (IoU) threshold for NMS
max_det: 300  # maximum number of detections per image
half: False  # use half precision (FP16)
dnn: False  # use OpenCV DNN for ONNX inference
plots: True  # save plots during train/val

# Prediction settings --------------------------------------------------------------------------------------------------
source:  # source directory for images or videos
show: False  # show results if possible
save_txt: False  # save results as .txt file
save_conf: False  # save results with confidence scores
save_crop: False  # save cropped images with results
hide_labels: False  # hide labels
hide_conf: False  # hide confidence scores
vid_stride: 1  # video frame-rate stride
line_thickness: 3  # bounding box thickness (pixels)
visualize: False  # visualize model features
augment: False  # apply image augmentation to prediction sources
agnostic_nms: False  # class-agnostic NMS
classes:  # filter results by class, i.e. class=0, or class=[0,2,3]
retina_masks: False  # use high-resolution segmentation masks
boxes: True  # Show boxes in segmentation predictions

# Export settings ------------------------------------------------------------------------------------------------------
format: torchscript  # format to export to
keras: False  # use Keras
optimize: False  # TorchScript: optimize for mobile
int8: False  # CoreML/TF INT8 quantization
dynamic: False  # ONNX/TF/TensorRT: dynamic axes
simplify: False  # ONNX: simplify model
opset:  # ONNX: opset version (optional)
workspace: 4  # TensorRT: workspace size (GB)
nms: False  # CoreML: add NMS

# Hyperparameters ------------------------------------------------------------------------------------------------------
lr0: 0.01  # initial learning rate (i.e. SGD=1E-2, Adam=1E-3)
lrf: 0.01  # final learning rate (lr0 * lrf)
momentum: 0.937  # SGD momentum/Adam beta1
weight_decay: 0.0005  # optimizer weight decay 5e-4
warmup_epochs: 3.0  # warmup epochs (fractions ok)
warmup_momentum: 0.8  # warmup initial momentum
warmup_bias_lr: 0.1  # warmup initial bias lr
box: 7.5  # box loss gain
cls: 0.5  # cls loss gain (scale with pixels)
dfl: 1.5  # dfl loss gain
fl_gamma: 0.0  # focal loss gamma (efficientDet default gamma=1.5)
label_smoothing: 0.0  # label smoothing (fraction)
nbs: 64  # nominal batch size
hsv_h: 0.015  # image HSV-Hue augmentation (fraction)
hsv_s: 0.7  # image HSV-Saturation augmentation (fraction)
hsv_v: 0.4  # image HSV-Value augmentation (fraction)
degrees: 0.0  # image rotation (+/- deg)
translate: 0.1  # image translation (+/- fraction)
scale: 0.5  # image scale (+/- gain)
shear: 0.0  # image shear (+/- deg)
perspective: 0.0  # image perspective (+/- fraction), range 0-0.001
flipud: 0.0  # image flip up-down (probability)
fliplr: 0.5  # image flip left-right (probability)
mosaic: 1.0  # image mosaic (probability)
mixup: 0.0  # image mixup (probability)
copy_paste: 0.0  # segment copy-paste (probability)

# Custom config.yaml ---------------------------------------------------------------------------------------------------
cfg:  # for overriding defaults.yaml

# Debug, do not modify -------------------------------------------------------------------------------------------------
v5loader: False  # use legacy YOLOv5 dataloader

# Tracker settings ------------------------------------------------------------------------------------------------------
tracker: botsort.yaml  # tracker type, ['botsort.yaml', 'bytetrack.yaml']
```





# [Configuration](https://docs.ultralytics.com/usage/cfg/)

YOLO settings and hyperparameters play a critical role in the model's performance, speed, and accuracy. These settings and hyperparameters can affect the model's behavior at various stages of the model development process, including training, validation, and prediction.

YOLOv8 'yolo' CLI commands use the following syntax:

```sh
yolo TASK MODE ARGS
yolo task=detect    mode=train    model=yolov8n.pt        args...
          classify       predict        yolov8n-cls.yaml  args...
          segment        val            yolov8n-seg.yaml  args...
                         export         yolov8n.pt        format=onnx  args...

# example    后面必须使用 = 
yolo predict model=yolov8n.pt source='https://ultralytics.com/images/bus.jpg'
yolo val detect data=coco.yaml device=0
yolo val detect data=coco128.yaml batch=1 device=0|cpu
```

Where:

- `TASK` (optional) is one of `[detect, segment, classify, pose]`. If it is not passed explicitly YOLOv8 will try to guess the `TASK` from the model type.
- `MODE` (required) is one of `[train, val, predict, export, track, benchmark]`
- `ARGS` (optional) are any number of custom `arg=value` pairs like `imgsz=320` that override defaults. For a full list of available `ARGS` see the [Configuration](https://docs.ultralytics.com/usage/cfg/) page and `defaults.yaml` GitHub [source](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/yolo/cfg/default.yaml).

## Tasks

YOLO models can be used for a variety of tasks, including detection, segmentation, classification and pose. These tasks differ in the type of output they produce and the specific problem they are designed to solve.

- **Detect**: For identifying and localizing objects or regions of interest in an image or video.
- **Segment**: For dividing an image or video into regions or pixels that correspond to different objects or classes.
- **Classify**: For predicting the class label of an input image.
- **Pose**: For identifying objects and estimating their keypoints in an image or video.

| Key    | Value      | Description                                     |
| :----- | :--------- | :---------------------------------------------- |
| `task` | `'detect'` | YOLO task, i.e. detect, segment, classify, pose |

## Modes

YOLO models can be used in different modes depending on the specific problem you are trying to solve. These modes include:

- **Train**: For training a YOLOv8 model on a custom dataset.

- **Val**: For validating a YOLOv8 model after it has been trained.

- **Predict**: For making predictions using a trained YOLOv8 model on new images or videos.

- **Export**: For exporting a YOLOv8 model to a format that can be used for deployment.

- **Track**: For tracking objects in real-time using a YOLOv8 model.

- **Benchmark**: For benchmarking YOLOv8 exports (ONNX, TensorRT, etc.) speed and accuracy.

| Key    | Value     | Description                                                  |
| :----- | :-------- | :----------------------------------------------------------- |
| `mode` | `'train'` | YOLO mode, i.e. train, val, predict, export, track, benchmark |

# 数据集

> 先要把数据集放入dataset中，修改data/目录下的yaml，调整为自己的数据集，需要调整路径，分类数，标签名

> yolo数据集格式(yolov5的coco128和霹雳吧啦Wz的yolo3为例)
>
> txt内容，每一行都是 `3 0.933536 0.486124 0.030408 0.154487`
>
> 是 label 中心横坐标与图像宽度比值 中心纵坐标与图像高度比值 bbox宽度与图像宽度比值 bbox高度与图像宽高比值

```
#-------------------------------------------#
# 	yolov5的coco128格式
# 	需要在~data/coco128.yaml中修改如下信息
# 	nc: 10  # 分类数要和dataset中一致
# 	names: ["aeroplane", "bicycle", "bird", "boat", "bottle": 5] # 分类名称
#-------------------------------------------#
datasets
├── coco128
	├── images
    │	├── train2017	训练图片
    │	└── val2017		验证图片
	└── labels
    	├── train2017	训练标签txt
    	└── val2017		验证标签txt


#-------------------------------------------#
#	霹雳吧啦Wz的yolo3
#-------------------------------------------#
data
├── pascal_voc_classes.json		存放类别信息 {"aeroplane": 1, "bicycle": 2, "bird": 3, "boat": 4, "bottle": 5}
├── train
│	├── images		训练图片
│	└── labels		训练标签txt
└── val
	├── images		验证图片
	└── labels		验证图片txt
```

> data/class20.yaml

```yaml
# YOLOv5 🚀 by Ultralytics, GPL-3.0 license
# COCO128 dataset https://www.kaggle.com/ultralytics/coco128 (first 128 images from COCO train2017) by Ultralytics
# Example usage: python train.py --data coco128.yaml
# parent
# ├── yolov5
# └── datasets
#     └── yourname
#         └── images/
#             └── train2017/  存放训练图片
#             └── val2017/    存放验证图片
#         └── labels/
#             └── train2017/  存放训练标签  class x_center y_center width height
#             └── val2017/    存放验证标签


# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]
path: ./datasets/coco128  # dataset root dir
train: images/train2017  # train images (relative to 'path') 128 images
val: images/val2017  # val images (relative to 'path') 128 images
test:  # test images (optional)

# Classes
names:
  0: aeroplane
  1: bicycle
  2: bird
  3: boat
  4: bottle
  5: bus
  6: car
  7: cat
  8: chair
  9: cow
  10: diningtable
  11: dog
  12: horse
  13: motorbike
  14: person
  15: pottedplant
  16: sheep
  17: sofa
  18: train
  19: tvmonitor
```

# 模型

> 然后在`models/yolov5*.yaml`中设置分类数

```yaml
# Parameters
nc: 20  # 调整为自己的分类数
```

# 下载权重

> 将下载好的权重放到`weights/`文件下下

## 模型

所有 YOLOv8 的预训练模型都可以在这里找到。目标检测和分割模型是在 COCO 数据集上预训练的，而分类模型是在 ImageNet 数据集上预训练的。

第一次使用时，[模型](https://github.com/ultralytics/ultralytics/tree/main/ultralytics/models) 会从 Ultralytics [发布页](https://github.com/ultralytics/ultralytics/releases) 自动下载。

| 模型                                                         | 尺寸 （像素） | mAPval 50-95 | 推理速度 CPU ONNX (ms) | 推理速度 A100 TensorRT (ms) | 参数量 (M) | FLOPs (B) |
| ------------------------------------------------------------ | ------------- | ------------ | ---------------------- | --------------------------- | ---------- | --------- |
| [YOLOv8n](https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt) | 640           | 37.3         | 80.4                   | 0.99                        | 3.2        | 8.7       |
| [YOLOv8s](https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8s.pt) | 640           | 44.9         | 128.4                  | 1.20                        | 11.2       | 28.6      |
| [YOLOv8m](https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m.pt) | 640           | 50.2         | 234.7                  | 1.83                        | 25.9       | 78.9      |
| [YOLOv8l](https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8l.pt) | 640           | 52.9         | 375.2                  | 2.39                        | 43.7       | 165.2     |
| [YOLOv8x](https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8x.pt) | 640           | 53.9         | 479.1                  | 3.53                        | 68.2       | 257.8     |

- **mAPval** 结果都在 [COCO val2017](http://cocodataset.org/) 数据集上，使用单模型单尺度测试得到。
  复现命令 `yolo val detect data=coco.yaml device=0`
- **推理速度**使用 COCO 验证集图片推理时间进行平均得到，测试环境使用 [Amazon EC2 P4d](https://aws.amazon.com/ec2/instance-types/p4/) 实例。
  复现命令 `yolo val detect data=coco128.yaml batch=1 device=0|cpu`

# 显卡训练

Training settings for YOLO models refer to the various hyperparameters and configurations used to train the model on a dataset. These settings can affect the model's performance, speed, and accuracy. Some common YOLO training settings include the batch size, learning rate, momentum, and weight decay. Other factors that may affect the training process include the choice of optimizer, the choice of loss function, and the size and composition of the training dataset. It is important to carefully tune and experiment with these settings to achieve the best possible performance for a given task.

| Key               | Value    | Description                                                  |
| :---------------- | :------- | :----------------------------------------------------------- |
| `model`           | `None`   | path to model file, i.e. yolov8n.pt, yolov8n.yaml            |
| `data`            | `None`   | path to data file, i.e. coco128.yaml                         |
| `epochs`          | `100`    | number of epochs to train for                                |
| `patience`        | `50`     | epochs to wait for no observable improvement for early stopping of training |
| `batch`           | `16`     | number of images per batch (-1 for AutoBatch)                |
| `imgsz`           | `640`    | size of input images as integer or w,h                       |
| `save`            | `True`   | save train checkpoints and predict results                   |
| `save_period`     | `-1`     | Save checkpoint every x epochs (disabled if < 1)             |
| `cache`           | `False`  | True/ram, disk or False. Use cache for data loading          |
| `device`          | `None`   | device to run on, i.e. cuda device=0 or device=0,1,2,3 or device=cpu |
| `workers`         | `8`      | number of worker threads for data loading (per RANK if DDP)  |
| `project`         | `None`   | project name                                                 |
| `name`            | `None`   | experiment name                                              |
| `exist_ok`        | `False`  | whether to overwrite existing experiment                     |
| `pretrained`      | `False`  | whether to use a pretrained model                            |
| `optimizer`       | `'SGD'`  | optimizer to use, choices=['SGD', 'Adam', 'AdamW', 'RMSProp'] |
| `verbose`         | `False`  | whether to print verbose output                              |
| `seed`            | `0`      | random seed for reproducibility                              |
| `deterministic`   | `True`   | whether to enable deterministic mode                         |
| `single_cls`      | `False`  | train multi-class data as single-class                       |
| `image_weights`   | `False`  | use weighted image selection for training                    |
| `rect`            | `False`  | support rectangular training                                 |
| `cos_lr`          | `False`  | use cosine learning rate scheduler                           |
| `close_mosaic`    | `10`     | disable mosaic augmentation for final 10 epochs              |
| `resume`          | `False`  | resume training from last checkpoint                         |
| `amp`             | `True`   | Automatic Mixed Precision (AMP) training, choices=[True, False] |
| `lr0`             | `0.01`   | initial learning rate (i.e. SGD=1E-2, Adam=1E-3)             |
| `lrf`             | `0.01`   | final learning rate (lr0 * lrf)                              |
| `momentum`        | `0.937`  | SGD momentum/Adam beta1                                      |
| `weight_decay`    | `0.0005` | optimizer weight decay 5e-4                                  |
| `warmup_epochs`   | `3.0`    | warmup epochs (fractions ok)                                 |
| `warmup_momentum` | `0.8`    | warmup initial momentum                                      |
| `warmup_bias_lr`  | `0.1`    | warmup initial bias lr                                       |
| `box`             | `7.5`    | box loss gain                                                |
| `cls`             | `0.5`    | cls loss gain (scale with pixels)                            |
| `dfl`             | `1.5`    | dfl loss gain                                                |
| `fl_gamma`        | `0.0`    | focal loss gamma (efficientDet default gamma=1.5)            |
| `label_smoothing` | `0.0`    | label smoothing (fraction)                                   |
| `nbs`             | `64`     | nominal batch size                                           |
| `overlap_mask`    | `True`   | masks should overlap during training (segment train only)    |
| `mask_ratio`      | `4`      | mask downsample ratio (segment train only)                   |
| `dropout`         | `0.0`    | use dropout regularization (classify train only)             |
| `val`             | `True`   | validate/test during training                                |

> `SGD`

```sh
yolo task=detect mode=train imgsz=640 batch=-1 epochs=300 optimizer=SGD lr0=0.01 cos_lr=True device=0 pretrained=True model=ultralytics/models/v8/yolov8n.yaml data=ultralytics/datasets/coco128.yaml
yolo task=detect mode=train imgsz=640 batch=-1 epochs=300 optimizer=SGD lr0=0.01 cos_lr=True device=0 pretrained=True model=ultralytics/models/v8/yolov8s.yaml data=ultralytics/datasets/coco128.yaml
yolo task=detect mode=train imgsz=640 batch=-1 epochs=300 optimizer=SGD lr0=0.01 cos_lr=True device=0 pretrained=True model=ultralytics/models/v8/yolov8m.yaml data=ultralytics/datasets/coco128.yaml
yolo task=detect mode=train imgsz=640 batch=-1 epochs=300 optimizer=SGD lr0=0.01 cos_lr=True device=0 pretrained=True model=ultralytics/models/v8/yolov8l.yaml data=ultralytics/datasets/coco128.yaml
yolo task=detect mode=train imgsz=640 batch=-1 epochs=300 optimizer=SGD lr0=0.01 cos_lr=True device=0 pretrained=True model=ultralytics/models/v8/yolov8x.yaml data=ultralytics/datasets/coco128.yaml
```

> `Adam`

```sh
yolo task=detect mode=train imgsz=640 batch=-1 epochs=300 optimizer=AdamW lr0=0.001 cos_lr=True device=0 pretrained=True model=ultralytics/models/v8/yolov8n.yaml data=ultralytics/datasets/coco128.yaml
yolo task=detect mode=train imgsz=640 batch=-1 epochs=300 optimizer=AdamW lr0=0.001 cos_lr=True device=0 pretrained=True model=ultralytics/models/v8/yolov8s.yaml data=ultralytics/datasets/coco128.yaml
yolo task=detect mode=train imgsz=640 batch=-1 epochs=300 optimizer=AdamW lr0=0.001 cos_lr=True device=0 pretrained=True model=ultralytics/models/v8/yolov8m.yaml data=ultralytics/datasets/coco128.yaml
yolo task=detect mode=train imgsz=640 batch=-1 epochs=300 optimizer=AdamW lr0=0.001 cos_lr=True device=0 pretrained=True model=ultralytics/models/v8/yolov8l.yaml data=ultralytics/datasets/coco128.yaml
yolo task=detect mode=train imgsz=640 batch=-1 epochs=300 optimizer=AdamW lr0=0.001 cos_lr=True device=0 pretrained=True model=ultralytics/models/v8/yolov8x.yaml data=ultralytics/datasets/coco128.yaml
```



# export

Export settings for YOLO models refer to the various configurations and options used to save or export the model for use in other environments or platforms. These settings can affect the model's performance, size, and compatibility with different systems. Some common YOLO export settings include the format of the exported model file (e.g. ONNX, TensorFlow SavedModel), the device on which the model will be run (e.g. CPU, GPU), and the presence of additional features such as masks or multiple labels per box. Other factors that may affect the export process include the specific task the model is being used for and the requirements or constraints of the target environment or platform. It is important to carefully consider and configure these settings to ensure that the exported model is optimized for the intended use case and can be used effectively in the target environment.

| Key         | Value           | Description                                          |
| :---------- | :-------------- | :--------------------------------------------------- |
| `format`    | `'torchscript'` | format to export to                                  |
| `imgsz`     | `640`           | image size as scalar or (h, w) list, i.e. (640, 480) |
| `keras`     | `False`         | use Keras for TF SavedModel export                   |
| `optimize`  | `False`         | TorchScript: optimize for mobile                     |
| `half`      | `False`         | FP16 quantization                                    |
| `int8`      | `False`         | INT8 quantization                                    |
| `dynamic`   | `False`         | ONNX/TF/TensorRT: dynamic axes                       |
| `simplify`  | `False`         | ONNX: simplify model                                 |
| `opset`     | `None`          | ONNX: opset version (optional, defaults to latest)   |
| `workspace` | `4`             | TensorRT: workspace size (GB)                        |
| `nms`       | `False`         | CoreML: add NMS                                      |

| Format                                                       | `format=`     | Model                     |
| :----------------------------------------------------------- | :------------ | :------------------------ |
| [PyTorch](https://pytorch.org/)                              | -             | `yolov8n.pt`              |
| [TorchScript](https://pytorch.org/docs/stable/jit.html)      | `torchscript` | `yolov8n.torchscript`     |
| [ONNX](https://onnx.ai/)                                     | `onnx`        | `yolov8n.onnx`            |
| [OpenVINO](https://docs.openvino.ai/latest/index.html)       | `openvino`    | `yolov8n_openvino_model/` |
| [TensorRT](https://developer.nvidia.com/tensorrt)            | `engine`      | `yolov8n.engine`          |
| [CoreML](https://github.com/apple/coremltools)               | `coreml`      | `yolov8n.mlmodel`         |
| [TensorFlow SavedModel](https://www.tensorflow.org/guide/saved_model) | `saved_model` | `yolov8n_saved_model/`    |
| [TensorFlow GraphDef](https://www.tensorflow.org/api_docs/python/tf/Graph) | `pb`          | `yolov8n.pb`              |
| [TensorFlow Lite](https://www.tensorflow.org/lite)           | `tflite`      | `yolov8n.tflite`          |
| [TensorFlow Edge TPU](https://coral.ai/docs/edgetpu/models-intro/) | `edgetpu`     | `yolov8n_edgetpu.tflite`  |
| [TensorFlow.js](https://www.tensorflow.org/js)               | `tfjs`        | `yolov8n_web_model/`      |
| [PaddlePaddle](https://github.com/PaddlePaddle)              | `paddle`      | `yolov8n_paddle_model/`   |

## torchscript

```sh
yolo task=detect mode=export imgsz=640 model=weights/yolov8s.pt format=torchscript optimize=True device=0
```

## onnx

> 注意:
>
> `onnxruntime` 和 `onnxruntime-gpu` 不要同时安装，否则使用 `gpu` 推理时速度会很慢，如果同时安装了2个包，要全部卸载，再安装`onnxruntime-gpu` 才能使用gpu推理，否则gpu速度会很慢

```sh
yolo task=detect mode=export imgsz=640 model=weights/yolov8s.pt format=onnx simplify=True
```

## openvino

```sh
yolo task=detect mode=export imgsz=640 model=weights/yolov8s.pt format=openvino
```

### 通过openvino的`mo`命令将onnx转换为openvino格式(支持**fp16**)

> https://docs.openvino.ai/latest/notebooks/102-pytorch-onnx-to-openvino-with-output.html

```sh
mo --input_model "onnx_path" --output_dir "output_path" --compress_to_fp16

mo --input_model "onnx_path" --output_dir "output_path" --compress_to_fp16
```

#### 代码方式

```python
from openvino.tools import mo
from openvino.runtime import serialize

onnx_path = "onnx_path"

# fp32 IR model
fp32_path = "fp32_path"
output_path = fp32_path + ".xml"
print(f"Export ONNX to OpenVINO FP32 IR to: {output_path}")
model = mo.convert_model(onnx_path)
serialize(model, output_path)

# fp16 IR model
fp16_path = "fp16_path"
output_path = fp16_path + ".xml"

print(f"Export ONNX to OpenVINO FP16 IR to: {output_path}")
model = mo.convert_model(onnx_path, compress_to_fp16=True)
serialize(model, output_path)
```

### export failure  0.9s: DLL load failed while importing ie_api

> https://blog.csdn.net/qq_26815239/article/details/123047840
>
> 如果你使用的是 Python 3.8 或更高版本，并且是在Windows系统下通过pip安装的openvino，那么该错误的解决方案如下：

1. 进入目录 `your\env\site-packages\openvino\inference_engine`
2. 打开文件 `__init__.py`
3. 26行下添加一行

```python
        if os.path.isdir(lib_path):
            # On Windows, with Python >= 3.8, DLLs are no longer imported from the PATH.
            if (3, 8) <= sys.version_info:
                os.add_dll_directory(os.path.abspath(lib_path))
                os.environ['PATH'] = os.path.abspath(lib_path) + ';' + os.environ['PATH']	# 添加这一行
```

## tensorrt

```sh
yolo task=detect mode=export imgsz=640 model=weights/yolov8s.pt format=engine half=True device=0
```

## onnx openvino tensorrt

```sh
yolo task=detect mode=export imgsz=640 model=weights/yolov8s.pt format=onnx,openvino,engine simplify=True device=0 half=True
```

# detect

Prediction settings for YOLO models refer to the various hyperparameters and configurations used to make predictions with the model on new data. These settings can affect the model's performance, speed, and accuracy. Some common YOLO prediction settings include the confidence threshold, non-maximum suppression (NMS) threshold, and the number of classes to consider. Other factors that may affect the prediction process include the size and format of the input data, the presence of additional features such as masks or multiple labels per box, and the specific task the model is being used for. It is important to carefully tune and experiment with these settings to achieve the best possible performance for a given task.

| Key              | Value                  | Description                                              |
| :--------------- | :--------------------- | :------------------------------------------------------- |
| `source`         | `'ultralytics/assets'` | source directory for images or videos                    |
| `conf`           | `0.25`                 | object confidence threshold for detection                |
| `iou`            | `0.7`                  | intersection over union (IoU) threshold for NMS          |
| `half`           | `False`                | use half precision (FP16)                                |
| `device`         | `None`                 | device to run on, i.e. cuda device=0/1/2/3 or device=cpu |
| `show`           | `False`                | show results if possible                                 |
| `save`           | `False`                | save images with results                                 |
| `save_txt`       | `False`                | save results as .txt file                                |
| `save_conf`      | `False`                | save results with confidence scores                      |
| `save_crop`      | `False`                | save cropped images with results                         |
| `hide_labels`    | `False`                | hide labels                                              |
| `hide_conf`      | `False`                | hide confidence scores                                   |
| `max_det`        | `300`                  | maximum number of detections per image                   |
| `vid_stride`     | `False`                | video frame-rate stride                                  |
| `line_thickness` | `3`                    | bounding box thickness (pixels)                          |
| `visualize`      | `False`                | visualize model features                                 |
| `augment`        | `False`                | apply image augmentation to prediction sources           |
| `agnostic_nms`   | `False`                | class-agnostic NMS                                       |
| `retina_masks`   | `False`                | use high-resolution segmentation masks                   |
| `classes`        | `None`                 | filter results by class, i.e. class=0, or class=[0,2,3]  |
| `boxes`          | `True`                 | Show boxes in segmentation predictions                   |

## torch

```sh
yolo task=detect mode=detect imgsz=640 save=True model=weights/yolov8n.pt source=data/images/bus.jpg device=0

yolo task=detect mode=detect imgsz=640 save=True model=weights/yolov8n.pt source=../datasets/coco128/images/train2017 device=0
```

## torchscript

```sh
yolo task=detect mode=detect imgsz=640 save=True model=weights/yolov8s.torchscript source=data/images/bus.jpg device=0

yolo task=detect mode=detect imgsz=640 save=True model=weights/yolov8s.torchscript source=../datasets/coco128/images/train2017 device=0
```

## onnx

> 注意:
>
> `onnxruntime` 和 `onnxruntime-gpu` 不要同时安装，否则使用 `gpu` 推理时速度会很慢，如果同时安装了2个包，要全部卸载，再安装 `onnxruntime-gpu` 才能使用gpu推理，否则gpu速度会很慢

```sh
yolo task=detect mode=detect imgsz=640 save=True model=weights/yolov8s.onnx source=data/images/bus.jpg device=0

yolo task=detect mode=detect imgsz=640 save=True model=weights/yolov8s.onnx source=../datasets/coco128/images/train2017 device=0
```

## openvino

> 注意：openvino没法使用cuda，但是使用 --device 0 会提高推理速度

```sh
yolo task=detect mode=detect imgsz=640 save=True model=weights/yolov8s_openvino_model source=data/images/bus.jpg device=cpu

yolo task=detect mode=detect imgsz=640 save=True model=weights/yolov8s_openvino_model source=../datasets/coco128/images/train2017 device=cpu
```

## tensorrt

```sh
yolo task=detect mode=detect imgsz=640 save=True model=weights/yolov8s.engine source=data/images/bus.jpg device=0

yolo task=detect mode=detect imgsz=640 save=True model=weights/yolov8s.engine source=../datasets/coco128/images/train2017 device=0
```

# val

Validation settings for YOLO models refer to the various hyperparameters and configurations used to evaluate the model's performance on a validation dataset. These settings can affect the model's performance, speed, and accuracy. Some common YOLO validation settings include the batch size, the frequency with which validation is performed during training, and the metrics used to evaluate the model's performance. Other factors that may affect the validation process include the size and composition of the validation dataset and the specific task the model is being used for. It is important to carefully tune and experiment with these settings to ensure that the model is performing well on the validation dataset and to detect and prevent overfitting.

| Key           | Value   | Description                                                  |
| :------------ | :------ | :----------------------------------------------------------- |
| `save_json`   | `False` | save results to JSON file                                    |
| `save_hybrid` | `False` | save hybrid version of labels (labels + additional predictions) |
| `conf`        | `0.001` | object confidence threshold for detection                    |
| `iou`         | `0.6`   | intersection over union (IoU) threshold for NMS              |
| `max_det`     | `300`   | maximum number of detections per image                       |
| `half`        | `True`  | use half precision (FP16)                                    |
| `device`      | `None`  | device to run on, i.e. cuda device=0/1/2/3 or device=cpu     |
| `dnn`         | `False` | use OpenCV DNN for ONNX inference                            |
| `plots`       | `False` | show plots during training                                   |
| `rect`        | `False` | support rectangular evaluation                               |
| `split`       | `val`   | dataset split to use for validation, i.e. 'val', 'test' or 'train' |

## torch

```sh
yolo task=detect mode=val imgsz=640 model=weights/yolov8s.pt save_json=True save_hybrid=True save_txt=True save_conf=True device=0
```

## torchscript

```sh
yolo task=detect mode=val imgsz=640 model=weights/yolov8s.torchscript save_json=True save_hybrid=True save_txt=True save_conf=True device=0
```

## onnx

> 注意:
>
> `onnxruntime` 和 `onnxruntime-gpu` 不要同时安装，否则使用 `gpu` 推理时速度会很慢，如果同时安装了2个包，要全部卸载，再安装 `onnxruntime-gpu` 才能使用gpu推理，否则gpu速度会很慢

```sh
yolo task=detect mode=val imgsz=640 model=weights/yolov8s.onnx save_json=True save_hybrid=True save_txt=True save_conf=True device=0
```

## openvino

> 注意：openvino没法使用cuda，但是使用 --device 0 会提高推理速度

```sh
yolo task=detect mode=val imgsz=640 model=weights/yolov8s_openvnio_model save_json=True save_hybrid=True save_txt=True save_conf=True device=cpu
```

## tensorrt

```sh
yolo task=detect mode=val imgsz=640 model=weights/yolov8s.onnx save_json=True save_hybrid=True device=0 save_txt=True save_conf=True half=True
```

