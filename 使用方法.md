

# æœ¬åœ°å®‰è£…

```sh
git clone https://github.com/ultralytics/ultralytics
cd ultralytics
pip install -v -e .
# "-v" æŒ‡è¯¦ç»†è¯´æ˜ï¼Œæˆ–æ›´å¤šçš„è¾“å‡º
# "-e" è¡¨ç¤ºåœ¨å¯ç¼–è¾‘æ¨¡å¼ä¸‹å®‰è£…é¡¹ç›®ï¼Œå› æ­¤å¯¹ä»£ç æ‰€åšçš„ä»»ä½•æœ¬åœ°ä¿®æ”¹éƒ½ä¼šç”Ÿæ•ˆï¼Œä»è€Œæ— éœ€é‡æ–°å®‰è£…ã€‚
```

# [CLI](https://docs.ultralytics.com/usage/cli/)

The YOLO Command Line Interface (CLI) is the easiest way to get started training, validating, predicting and exporting YOLOv8 models.

The `yolo` command is used for all actions:

```sh
yolo TASK MODE ARGS

Where   TASK (optional) is one of [detect, segment, classify]
        MODE (required) is one of [train, val, predict, export, track]
        ARGS (optional) are any number of custom 'arg=value' pairs like 'imgsz=320' that override defaults.
```

Where:

- `TASK` (optional) is one of `[detect, segment, classify]`. If it is not passed explicitly YOLOv8 will try to guess the `TASK` from the model type.
- `MODE` (required) is one of `[train, val, predict, export, track]`
- `ARGS` (optional) are any number of custom `arg=value` pairs like `imgsz=320` that override defaults. For a full list of available `ARGS` see the [Configuration](https://docs.ultralytics.com/usage/cfg/) page and `defaults.yaml` GitHub [source](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/default.yaml).

Arguments must be passed as `arg=val` pairs, split by an equals `=` sign and delimited by spaces between pairs. Do not use `--` argument prefixes or commas `,` between arguments.

- `yolo predict model=yolov8n.pt imgsz=640 conf=0.25`  âœ…
- `yolo predict model yolov8n.pt imgsz 640 conf 0.25`  âŒ
- `yolo predict --model yolov8n.pt --imgsz 640 --conf 0.25`  âŒ

## Overriding default arguments

Default arguments can be overridden by simply passing them as arguments in the CLI in `arg=value` pairs.

```sh
yolo detect train data=coco128.yaml model=yolov8n.pt epochs=10 lr0=0.01
yolo segment predict model=yolov8n-seg.pt source='https://youtu.be/LNwODJXcvt4' imgsz=320
yolo detect val model=yolov8n.pt data=coco128.yaml batch=1 imgsz=640
```

## Overriding default config file

You can override the `default.yaml` config file entirely by passing a new file with the `cfg` arguments, i.e. `cfg=custom.yaml`.

To do this first create a copy of `default.yaml` in your current working dir with the `yolo copy-cfg` command.

This will create `default_copy.yaml`, which you can then pass as `cfg=default_copy.yaml` along with any additional args, like `imgsz=320` in this example:



```sh
yolo copy-cfg
yolo cfg=default_copy.yaml imgsz=320
```

## é»˜è®¤é…ç½®æ–‡ä»¶

> `ultralytics/cfg/default.yaml`

```yaml
# Ultralytics YOLO ğŸš€, AGPL-3.0 license
# Default training settings and hyperparameters for medium-augmentation COCO training

task: detect  # (str) YOLO task, i.e. detect, segment, classify, pose
mode: train  # (str) YOLO mode, i.e. train, val, predict, export, track, benchmark

# Train settings -------------------------------------------------------------------------------------------------------
model:  # (str, optional) path to model file, i.e. yolov8n.pt, yolov8n.yaml
data:  # (str, optional) path to data file, i.e. coco128.yaml
epochs: 100  # (int) number of epochs to train for
time:  # (float, optional) number of hours to train for, overrides epochs if supplied
patience: 50  # (int) epochs to wait for no observable improvement for early stopping of training
batch: 16  # (int) number of images per batch (-1 for AutoBatch)
imgsz: 640  # (int | list) input images size as int for train and val modes, or list[w,h] for predict and export modes
save: True  # (bool) save train checkpoints and predict results
save_period: -1 # (int) Save checkpoint every x epochs (disabled if < 1)
cache: False  # (bool) True/ram, disk or False. Use cache for data loading
device:  # (int | str | list, optional) device to run on, i.e. cuda device=0 or device=0,1,2,3 or device=cpu
workers: 8  # (int) number of worker threads for data loading (per RANK if DDP)
project:  # (str, optional) project name
name:  # (str, optional) experiment name, results saved to 'project/name' directory
exist_ok: False  # (bool) whether to overwrite existing experiment
pretrained: True  # (bool | str) whether to use a pretrained model (bool) or a model to load weights from (str)
optimizer: auto  # (str) optimizer to use, choices=[SGD, Adam, Adamax, AdamW, NAdam, RAdam, RMSProp, auto]
verbose: True  # (bool) whether to print verbose output
seed: 0  # (int) random seed for reproducibility
deterministic: True  # (bool) whether to enable deterministic mode
single_cls: False  # (bool) train multi-class data as single-class
rect: False  # (bool) rectangular training if mode='train' or rectangular validation if mode='val'
cos_lr: False  # (bool) use cosine learning rate scheduler
close_mosaic: 10  # (int) disable mosaic augmentation for final epochs (0 to disable)
resume: False  # (bool) resume training from last checkpoint
amp: True  # (bool) Automatic Mixed Precision (AMP) training, choices=[True, False], True runs AMP check
fraction: 1.0  # (float) dataset fraction to train on (default is 1.0, all images in train set)
profile: False  # (bool) profile ONNX and TensorRT speeds during training for loggers
freeze: None  # (int | list, optional) freeze first n layers, or freeze list of layer indices during training
multi_scale: False   # (bool) Whether to use multi-scale during training
# Segmentation
overlap_mask: True  # (bool) masks should overlap during training (segment train only)
mask_ratio: 4  # (int) mask downsample ratio (segment train only)
# Classification
dropout: 0.0  # (float) use dropout regularization (classify train only)

# Val/Test settings ----------------------------------------------------------------------------------------------------
val: True  # (bool) validate/test during training
split: val  # (str) dataset split to use for validation, i.e. 'val', 'test' or 'train'
save_json: False  # (bool) save results to JSON file
save_hybrid: False  # (bool) save hybrid version of labels (labels + additional predictions)
conf:  # (float, optional) object confidence threshold for detection (default 0.25 predict, 0.001 val)
iou: 0.7  # (float) intersection over union (IoU) threshold for NMS
max_det: 300  # (int) maximum number of detections per image
half: False  # (bool) use half precision (FP16)
dnn: False  # (bool) use OpenCV DNN for ONNX inference
plots: True  # (bool) save plots and images during train/val

# Predict settings -----------------------------------------------------------------------------------------------------
source:  # (str, optional) source directory for images or videos
vid_stride: 1  # (int) video frame-rate stride
stream_buffer: False  # (bool) buffer all streaming frames (True) or return the most recent frame (False)
visualize: False  # (bool) visualize model features
augment: False  # (bool) apply image augmentation to prediction sources
agnostic_nms: False  # (bool) class-agnostic NMS
classes:  # (int | list[int], optional) filter results by class, i.e. classes=0, or classes=[0,2,3]
retina_masks: False  # (bool) use high-resolution segmentation masks
embed:  # (list[int], optional) return feature vectors/embeddings from given layers

# Visualize settings ---------------------------------------------------------------------------------------------------
show: False  # (bool) show predicted images and videos if environment allows
save_frames: False  # (bool) save predicted individual video frames
save_txt: False  # (bool) save results as .txt file
save_conf: False  # (bool) save results with confidence scores
save_crop: False  # (bool) save cropped images with results
show_labels: True  # (bool) show prediction labels, i.e. 'person'
show_conf: True  # (bool) show prediction confidence, i.e. '0.99'
show_boxes: True  # (bool) show prediction boxes
line_width:   # (int, optional) line width of the bounding boxes. Scaled to image size if None.

# Export settings ------------------------------------------------------------------------------------------------------
format: torchscript  # (str) format to export to, choices at https://docs.ultralytics.com/modes/export/#export-formats
keras: False  # (bool) use Kera=s
optimize: False  # (bool) TorchScript: optimize for mobile
int8: False  # (bool) CoreML/TF INT8 quantization
dynamic: False  # (bool) ONNX/TF/TensorRT: dynamic axes
simplify: False  # (bool) ONNX: simplify model
opset:  # (int, optional) ONNX: opset version
workspace: 4  # (int) TensorRT: workspace size (GB)
nms: False  # (bool) CoreML: add NMS

# Hyperparameters ------------------------------------------------------------------------------------------------------
lr0: 0.01  # (float) initial learning rate (i.e. SGD=1E-2, Adam=1E-3)
lrf: 0.01  # (float) final learning rate (lr0 * lrf)
momentum: 0.937  # (float) SGD momentum/Adam beta1
weight_decay: 0.0005  # (float) optimizer weight decay 5e-4
warmup_epochs: 3.0  # (float) warmup epochs (fractions ok)
warmup_momentum: 0.8  # (float) warmup initial momentum
warmup_bias_lr: 0.1  # (float) warmup initial bias lr
box: 7.5  # (float) box loss gain
cls: 0.5  # (float) cls loss gain (scale with pixels)
dfl: 1.5  # (float) dfl loss gain
pose: 12.0  # (float) pose loss gain
kobj: 1.0  # (float) keypoint obj loss gain
label_smoothing: 0.0  # (float) label smoothing (fraction)
nbs: 64  # (int) nominal batch size
hsv_h: 0.015  # (float) image HSV-Hue augmentation (fraction)
hsv_s: 0.7  # (float) image HSV-Saturation augmentation (fraction)
hsv_v: 0.4  # (float) image HSV-Value augmentation (fraction)
degrees: 0.0  # (float) image rotation (+/- deg)
translate: 0.1  # (float) image translation (+/- fraction)
scale: 0.5  # (float) image scale (+/- gain)
shear: 0.0  # (float) image shear (+/- deg)
perspective: 0.0  # (float) image perspective (+/- fraction), range 0-0.001
flipud: 0.0  # (float) image flip up-down (probability)
fliplr: 0.5  # (float) image flip left-right (probability)
mosaic: 1.0  # (float) image mosaic (probability)
mixup: 0.0  # (float) image mixup (probability)
copy_paste: 0.0  # (float) segment copy-paste (probability)
auto_augment: randaugment  # (str) auto augmentation policy for classification (randaugment, autoaugment, augmix)
erasing: 0.4  # (float) probability of random erasing during classification training (0-1)
crop_fraction: 1.0  # (float) image crop fraction for classification evaluation/inference (0-1)

# Custom config.yaml ---------------------------------------------------------------------------------------------------
cfg:  # (str, optional) for overriding defaults.yaml

# Tracker settings ------------------------------------------------------------------------------------------------------
tracker: botsort.yaml  # (str) tracker type, choices=[botsort.yaml, bytetrack.yaml]
```

## cli æ–‡ä»¶

> `ultralytics/cfg/__init__.py`

# [Configuration](https://docs.ultralytics.com/usage/cfg/)

YOLO settings and hyperparameters play a critical role in the model's performance, speed, and accuracy. These settings and hyperparameters can affect the model's behavior at various stages of the model development process, including training, validation, and prediction.

YOLOv8 'yolo' CLI commands use the following syntax:

```sh
yolo TASK MODE ARGS
yolo task=detect    mode=train    model=yolov8n.pt        args...
          classify       predict        yolov8n-cls.yaml  args...
          segment        val            yolov8n-seg.yaml  args...
                         export         yolov8n.pt        format=onnx  args...

# example    åé¢å¿…é¡»ä½¿ç”¨ =
yolo predict model=yolov8n.pt source='https://ultralytics.com/images/bus.jpg'
yolo val detect data=coco.yaml device=0
yolo val detect data=coco128.yaml batch=1 device=0|cpu
```

Where:

- `TASK` (optional) is one of `[detect, segment, classify, pose]`. If it is not passed explicitly YOLOv8 will try to guess the `TASK` from the model type.
- `MODE` (required) is one of `[train, val, predict, export, track, benchmark]`
- `ARGS` (optional) are any number of custom `arg=value` pairs like `imgsz=320` that override defaults. For a full list of available `ARGS` see the [Configuration](https://docs.ultralytics.com/usage/cfg/) page and `defaults.yaml` GitHub [source](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/default.yaml).

YOLO models can be used for a variety of tasks, including detection, segmentation, classification and pose. These tasks differ in the type of output they produce and the specific problem they are designed to solve.

- **Detect**: For identifying and localizing objects or regions of interest in an image or video.
- **Segment**: For dividing an image or video into regions or pixels that correspond to different objects or classes.
- **Classify**: For predicting the class label of an input image.
- **Pose**: For identifying objects and estimating their keypoints in an image or video.

| Key    | Value      | Description                                     |
| :----- | :--------- | :---------------------------------------------- |
| `task` | `'detect'` | YOLO task, i.e. detect, segment, classify, pose |

## Modes

YOLO models can be used in different modes depending on the specific problem you are trying to solve. These modes include:

- **Train**: For training a YOLOv8 model on a custom dataset.

- **Val**: For validating a YOLOv8 model after it has been trained.

- **Predict**: For making predictions using a trained YOLOv8 model on new images or videos.

- **Export**: For exporting a YOLOv8 model to a format that can be used for deployment.

- **Track**: For tracking objects in real-time using a YOLOv8 model.

- **Benchmark**: For benchmarking YOLOv8 exports (ONNX, TensorRT, etc.) speed and accuracy.

| Key    | Value     | Description                                                  |
| :----- | :-------- | :----------------------------------------------------------- |
| `mode` | `'train'` | YOLO mode, i.e. train, val, predict, export, track, benchmark |

# æ•°æ®é›†

> å…ˆè¦æŠŠæ•°æ®é›†æ”¾å…¥datasetä¸­ï¼Œä¿®æ”¹data/ç›®å½•ä¸‹çš„yamlï¼Œè°ƒæ•´ä¸ºè‡ªå·±çš„æ•°æ®é›†ï¼Œéœ€è¦è°ƒæ•´è·¯å¾„ï¼Œåˆ†ç±»æ•°ï¼Œæ ‡ç­¾å

> yoloæ•°æ®é›†æ ¼å¼(yolov5/v8çš„coco128å’Œéœ¹é›³å§å•¦Wzçš„yolo3ä¸ºä¾‹)
>
> txtå†…å®¹ï¼Œæ¯ä¸€è¡Œéƒ½æ˜¯ `3 0.933536 0.486124 0.030408 0.154487`
>
> æ˜¯ label ä¸­å¿ƒæ¨ªåæ ‡ä¸å›¾åƒå®½åº¦æ¯”å€¼ ä¸­å¿ƒçºµåæ ‡ä¸å›¾åƒé«˜åº¦æ¯”å€¼ bboxå®½åº¦ä¸å›¾åƒå®½åº¦æ¯”å€¼ bboxé«˜åº¦ä¸å›¾åƒå®½é«˜æ¯”å€¼

```sh
#-------------------------------------------#
# 	yolov5 v8çš„æ ¼å¼
#-------------------------------------------#
yaml:
    path: ../datasets/coco128   # dataset root dir
    train: images/train         # train images (relative to 'path') 128 images
    val: images/val             # val images (relative to 'path') 128 images
    test: images/test           # test images (optional)

dir:
    datasets
    â”œâ”€â”€ coco128
        â”œâ”€â”€ images
        â”‚   â”œâ”€â”€ train   # è®­ç»ƒå›¾ç‰‡
        â”‚   â”œâ”€â”€ val     # éªŒè¯å›¾ç‰‡
        â”‚   â””â”€â”€ test    # æµ‹è¯•å›¾ç‰‡
        â””â”€â”€ labels
            â”œâ”€â”€ train   # è®­ç»ƒæ ‡ç­¾txt
            â”œâ”€â”€ val     # éªŒè¯æ ‡ç­¾txt
            â””â”€â”€ test    # æµ‹è¯•æ ‡ç­¾txt

#-------------------------------------------#
# 	yolov5 v8å¦çš„ä¸€ç§å›¾ç‰‡ç›®å½•æ ¼å¼
#-------------------------------------------#
yaml:
    path: ../datasets/coco128   # dataset root dir
    train: train/images         # train images (relative to 'path')
    val: val/images             # val images (relative to 'path')
    test: test/images           # test images (optional)
dir:
    datasets
    â”œâ”€â”€ coco128
        â”œâ”€â”€ train
        â”‚   â”œâ”€â”€ images  # è®­ç»ƒå›¾ç‰‡
        â”‚   â””â”€â”€ labels  # è®­ç»ƒæ ‡ç­¾txt
        â”œâ”€â”€ val
        â”‚   â”œâ”€â”€ images  # éªŒè¯å›¾ç‰‡
        â”‚   â””â”€â”€ labels  # éªŒè¯æ ‡ç­¾txt
        â””â”€â”€ test
            â”œâ”€â”€ images  # æµ‹è¯•å›¾ç‰‡
            â””â”€â”€ labels  # æµ‹è¯•æ ‡ç­¾txt
```

> `ultralytics/datasets/class20.yaml`

```yaml
# YOLOv5 ğŸš€ by Ultralytics, GPL-3.0 license
# COCO128 dataset https://www.kaggle.com/ultralytics/coco128 (first 128 images from COCO train2017) by Ultralytics
# Example usage: python train.py --data coco128.yaml
# parent
# â”œâ”€â”€ ultralytics
# |   â””â”€â”€ ultralytics
# â””â”€â”€ datasets
#     â””â”€â”€ yourname
#         â””â”€â”€ images/
#             â””â”€â”€ train2017/  å­˜æ”¾è®­ç»ƒå›¾ç‰‡
#             â””â”€â”€ val2017/    å­˜æ”¾éªŒè¯å›¾ç‰‡
#         â””â”€â”€ labels/
#             â””â”€â”€ train2017/  å­˜æ”¾è®­ç»ƒæ ‡ç­¾  class x_center y_center width height
#             â””â”€â”€ val2017/    å­˜æ”¾éªŒè¯æ ‡ç­¾


# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]
path: ../datasets/classes20  # dataset root dir
train: images/train2017  # train images (relative to 'path') 128 images
val: images/val2017  # val images (relative to 'path') 128 images
test:  # test images (optional)

# Classes
names:
  0: aeroplane
  1: bicycle
  2: bird
  3: boat
  4: bottle
  5: bus
  6: car
  7: cat
  8: chair
  9: cow
  10: diningtable
  11: dog
  12: horse
  13: motorbike
  14: person
  15: pottedplant
  16: sheep
  17: sofa
  18: train
  19: tvmonitor
```

# ä¸‹è½½æƒé‡

> å°†ä¸‹è½½å¥½çš„æƒé‡æ”¾åˆ°`weights/`æ–‡ä»¶ä¸‹ä¸‹

## æ¨¡å‹

æ‰€æœ‰çš„ YOLOv8 é¢„è®­ç»ƒæ¨¡å‹éƒ½å¯ä»¥åœ¨æ­¤æ‰¾åˆ°ã€‚æ£€æµ‹ã€åˆ†å‰²å’Œå§¿æ€æ¨¡å‹åœ¨ [COCO](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/datasets/coco.yaml) æ•°æ®é›†ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œè€Œåˆ†ç±»æ¨¡å‹åœ¨ [ImageNet](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/datasets/ImageNet.yaml) æ•°æ®é›†ä¸Šè¿›è¡Œé¢„è®­ç»ƒã€‚

åœ¨é¦–æ¬¡ä½¿ç”¨æ—¶ï¼Œ[æ¨¡å‹](https://github.com/ultralytics/ultralytics/tree/main/ultralytics/models) ä¼šè‡ªåŠ¨ä»æœ€æ–°çš„ Ultralytics [å‘å¸ƒç‰ˆæœ¬](https://github.com/ultralytics/assets/releases)ä¸­ä¸‹è½½ã€‚

| æ¨¡å‹                                                         | å°ºå¯¸ ï¼ˆåƒç´ ï¼‰ | mAPval 50-95 | æ¨ç†é€Ÿåº¦ CPU ONNX (ms) | æ¨ç†é€Ÿåº¦ A100 TensorRT (ms) | å‚æ•°é‡ (M) | FLOPs (B) |
| ------------------------------------------------------------ | ------------- | ------------ | ---------------------- | --------------------------- | ---------- | --------- |
| [YOLOv8n](https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt) | 640           | 37.3         | 80.4                   | 0.99                        | 3.2        | 8.7       |
| [yolov8n](https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt) | 640           | 44.9         | 128.4                  | 1.20                        | 11.2       | 28.6      |
| [YOLOv8m](https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m.pt) | 640           | 50.2         | 234.7                  | 1.83                        | 25.9       | 78.9      |
| [YOLOv8l](https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8l.pt) | 640           | 52.9         | 375.2                  | 2.39                        | 43.7       | 165.2     |
| [YOLOv8x](https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8x.pt) | 640           | 53.9         | 479.1                  | 3.53                        | 68.2       | 257.8     |

- **mAPval** ç»“æœéƒ½åœ¨ [COCO val2017](http://cocodataset.org/) æ•°æ®é›†ä¸Šï¼Œä½¿ç”¨å•æ¨¡å‹å•å°ºåº¦æµ‹è¯•å¾—åˆ°ã€‚
  å¤ç°å‘½ä»¤ `yolo val detect data=coco.yaml device=0`
- **æ¨ç†é€Ÿåº¦**ä½¿ç”¨ COCO éªŒè¯é›†å›¾ç‰‡æ¨ç†æ—¶é—´è¿›è¡Œå¹³å‡å¾—åˆ°ï¼Œæµ‹è¯•ç¯å¢ƒä½¿ç”¨ [Amazon EC2 P4d](https://aws.amazon.com/ec2/instance-types/p4/) å®ä¾‹ã€‚
  å¤ç°å‘½ä»¤ `yolo val detect data=coco128.yaml batch=1 device=0|cpu`

# [è®­ç»ƒ](https://docs.ultralytics.com/zh/modes/train/)

## è®­ç»ƒæ¨¡å¼çš„å…³é”®ç‰¹æ€§

ä»¥ä¸‹æ˜¯YOLOv8è®­ç»ƒæ¨¡å¼çš„ä¸€äº›æ˜¾è‘—ç‰¹ç‚¹ï¼š

- **è‡ªåŠ¨æ•°æ®é›†ä¸‹è½½:** æ ‡å‡†æ•°æ®é›†å¦‚COCOã€VOCå’ŒImageNetå°†åœ¨é¦–æ¬¡ä½¿ç”¨æ—¶è‡ªåŠ¨ä¸‹è½½ã€‚
- **å¤šGPUæ”¯æŒ:** æ— ç¼åœ°è·¨å¤šä¸ªGPUæ‰©å±•æ‚¨çš„è®­ç»ƒå·¥ä½œï¼Œä»¥åŠ å¿«è¿‡ç¨‹ã€‚
- **è¶…å‚æ•°é…ç½®:** é€šè¿‡YAMLé…ç½®æ–‡ä»¶æˆ–CLIå‚æ•°ä¿®æ”¹è¶…å‚æ•°çš„é€‰é¡¹ã€‚
- **å¯è§†åŒ–å’Œç›‘æ§:** å®æ—¶è·Ÿè¸ªè®­ç»ƒæŒ‡æ ‡å¹¶å¯è§†åŒ–å­¦ä¹ è¿‡ç¨‹ï¼Œä»¥è·å¾—æ›´å¥½çš„æ´å¯ŸåŠ›ã€‚

## ä½¿ç”¨ç¤ºä¾‹

### **å•GPUå’ŒCPUè®­ç»ƒç¤ºä¾‹**

è®¾å¤‡å°†è‡ªåŠ¨ç¡®å®šã€‚å¦‚æœæœ‰å¯ç”¨çš„GPUï¼Œé‚£ä¹ˆå°†ä½¿ç”¨å®ƒï¼Œå¦åˆ™å°†åœ¨CPUä¸Šå¼€å§‹è®­ç»ƒã€‚

> python

```python
from ultralytics import YOLO

# åŠ è½½ä¸€ä¸ªæ¨¡å‹
model = YOLO('yolov8n.yaml')  # ä»YAMLå»ºç«‹ä¸€ä¸ªæ–°æ¨¡å‹
model = YOLO('yolov8n.pt')  # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ï¼ˆæ¨èç”¨äºè®­ç»ƒï¼‰
model = YOLO('yolov8n.yaml').load('yolov8n.pt')  # ä»YAMLå»ºç«‹å¹¶è½¬ç§»æƒé‡

# è®­ç»ƒæ¨¡å‹
results = model.train(data='coco128.yaml', epochs=100, imgsz=640)
```

```python
from ultralytics import YOLO

# yolo task=detect mode=train imgsz=640 batch=-1 workers=8 epochs=300 patience=0 close_mosaic=10
# fraction=1.0 cos_lr=True device=0 model=weights/yolov8n.pt data=ultralytics/cfg/datasets/coco128.yaml

# åŠ è½½ä¸€ä¸ªæ¨¡å‹
model = YOLO('weights/yolov8n.pt')  # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ï¼ˆæ¨èç”¨äºè®­ç»ƒï¼‰

# è®­ç»ƒæ¨¡å‹
results = model.train(
    imgsz=640,
    batch=-1,
    workers=8,
    epochs=300,
    patience=0,
    close_mosaic=10,
    fraction=1.0,
    cos_lr=True,
    device=0,
    data='ultralytics/cfg/datasets/coco128.yaml',
)

print(results)
```

> cli

```sh
# ä»YAMLæ„å»ºæ–°æ¨¡å‹ï¼Œä»å¤´å¼€å§‹è®­ç»ƒ
yolo detect train data=coco128.yaml model=yolov8n.yaml epochs=100 imgsz=640

# ä»é¢„è®­ç»ƒ*.ptæ¨¡å‹å¼€å§‹è®­ç»ƒ
yolo detect train data=coco128.yaml model=yolov8n.pt epochs=100 imgsz=640

# ä»YAMLæ„å»ºä¸€ä¸ªæ–°æ¨¡å‹ï¼Œè½¬ç§»é¢„è®­ç»ƒæƒé‡ï¼Œç„¶åå¼€å§‹è®­ç»ƒ
yolo detect train data=coco128.yaml model=yolov8n.yaml pretrained=yolov8n.pt epochs=100 imgsz=640
```

### å¤šGPUè®­ç»ƒ

å¤šGPUè®­ç»ƒé€šè¿‡åœ¨å¤šä¸ªGPUä¸Šåˆ†å¸ƒè®­ç»ƒè´Ÿè½½ï¼Œå®ç°å¯¹å¯ç”¨ç¡¬ä»¶èµ„æºçš„æ›´æœ‰æ•ˆåˆ©ç”¨ã€‚æ— è®ºæ˜¯é€šè¿‡Python APIè¿˜æ˜¯å‘½ä»¤è¡Œç•Œé¢ï¼Œéƒ½å¯ä»¥ä½¿ç”¨æ­¤åŠŸèƒ½ã€‚ è‹¥è¦å¯ç”¨å¤šGPUè®­ç»ƒï¼Œè¯·æŒ‡å®šæ‚¨å¸Œæœ›ä½¿ç”¨çš„GPUè®¾å¤‡IDã€‚

> python

```python
from ultralytics import YOLO

# åŠ è½½æ¨¡å‹
model = YOLO('yolov8n.pt')  # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ï¼ˆæ¨èç”¨äºè®­ç»ƒï¼‰

# ä½¿ç”¨2ä¸ªGPUè®­ç»ƒæ¨¡å‹
results = model.train(data='coco128.yaml', epochs=100, imgsz=640, device=[0, 1])
```

> cli

```sh
# ä½¿ç”¨GPU 0å’Œ1ä»é¢„è®­ç»ƒ*.ptæ¨¡å‹å¼€å§‹è®­ç»ƒ
yolo detect train data=coco128.yaml model=yolov8n.pt epochs=100 imgsz=640 device=0,1
```

### æ¢å¤ä¸­æ–­çš„è®­ç»ƒ

åœ¨å¤„ç†æ·±åº¦å­¦ä¹ æ¨¡å‹æ—¶ï¼Œä»ä¹‹å‰ä¿å­˜çš„çŠ¶æ€æ¢å¤è®­ç»ƒæ˜¯ä¸€ä¸ªå…³é”®ç‰¹æ€§ã€‚åœ¨å„ç§æƒ…å†µä¸‹ï¼Œè¿™å¯èƒ½å¾ˆæ–¹ä¾¿ï¼Œæ¯”å¦‚å½“è®­ç»ƒè¿‡ç¨‹æ„å¤–ä¸­æ–­ï¼Œæˆ–è€…å½“æ‚¨å¸Œæœ›ç”¨æ–°æ•°æ®æˆ–æ›´å¤šæ—¶æœŸç»§ç»­è®­ç»ƒæ¨¡å‹æ—¶ã€‚

æ¢å¤è®­ç»ƒæ—¶ï¼ŒUltralytics YOLOå°†åŠ è½½æœ€åä¿å­˜çš„æ¨¡å‹çš„æƒé‡ï¼Œå¹¶æ¢å¤ä¼˜åŒ–å™¨çŠ¶æ€ã€å­¦ä¹ ç‡è°ƒåº¦å™¨å’Œæ—¶æœŸç¼–å·ã€‚è¿™å…è®¸æ‚¨æ— ç¼åœ°ä»ç¦»å¼€çš„åœ°æ–¹ç»§ç»­è®­ç»ƒè¿‡ç¨‹ã€‚

åœ¨Ultralytics YOLOä¸­ï¼Œæ‚¨å¯ä»¥é€šè¿‡åœ¨è°ƒç”¨`train`æ–¹æ³•æ—¶å°†`resume`å‚æ•°è®¾ç½®ä¸º`True`å¹¶æŒ‡å®šåŒ…å«éƒ¨åˆ†è®­ç»ƒæ¨¡å‹æƒé‡çš„`.pt`æ–‡ä»¶è·¯å¾„æ¥è½»æ¾æ¢å¤è®­ç»ƒã€‚

ä¸‹é¢æ˜¯ä½¿ç”¨Pythonå’Œå‘½ä»¤è¡Œæ¢å¤ä¸­æ–­è®­ç»ƒçš„ç¤ºä¾‹ï¼š

> python

```python
from ultralytics import YOLO

# åŠ è½½æ¨¡å‹
model = YOLO('path/to/last.pt')  # åŠ è½½éƒ¨åˆ†è®­ç»ƒçš„æ¨¡å‹

# æ¢å¤è®­ç»ƒ
results = model.train(resume=True)
```

> cli

```sh
# æ¢å¤ä¸­æ–­çš„è®­ç»ƒ
yolo train resume model=path/to/last.pt
```

é€šè¿‡è®¾ç½®`resume=True`ï¼Œ`train`å‡½æ•°å°†ä»'path/to/last.pt'æ–‡ä»¶ä¸­å­˜å‚¨çš„çŠ¶æ€ç»§ç»­è®­ç»ƒã€‚å¦‚æœçœç•¥`resume`å‚æ•°æˆ–å°†å…¶è®¾ç½®ä¸º`False`ï¼Œ`train`å‡½æ•°å°†å¯åŠ¨æ–°çš„è®­ç»ƒä¼šè¯ã€‚

è¯·è®°ä½ï¼Œé»˜è®¤æƒ…å†µä¸‹ï¼Œæ£€æŸ¥ç‚¹ä¼šåœ¨æ¯ä¸ªæ—¶æœŸç»“æŸæ—¶ä¿å­˜ï¼Œæˆ–è€…ä½¿ç”¨`save_period`å‚æ•°ä»¥å›ºå®šé—´éš”ä¿å­˜ï¼Œå› æ­¤æ‚¨å¿…é¡»è‡³å°‘å®Œæˆ1ä¸ªæ—¶æœŸæ‰èƒ½æ¢å¤è®­ç»ƒè¿è¡Œã€‚

## å‚æ•°

YOLOæ¨¡å‹çš„è®­ç»ƒè®¾ç½®æ˜¯æŒ‡ç”¨äºå¯¹æ•°æ®é›†è¿›è¡Œæ¨¡å‹è®­ç»ƒçš„å„ç§è¶…å‚æ•°å’Œé…ç½®ã€‚è¿™äº›è®¾ç½®ä¼šå½±å“æ¨¡å‹çš„æ€§èƒ½ã€é€Ÿåº¦å’Œå‡†ç¡®æ€§ã€‚ä¸€äº›å¸¸è§çš„YOLOè®­ç»ƒè®¾ç½®åŒ…æ‹¬æ‰¹å¤§å°ã€å­¦ä¹ ç‡ã€åŠ¨é‡å’Œæƒé‡è¡°å‡ã€‚å…¶ä»–å¯èƒ½å½±å“è®­ç»ƒè¿‡ç¨‹çš„å› ç´ åŒ…æ‹¬ä¼˜åŒ–å™¨çš„é€‰æ‹©ã€æŸå¤±å‡½æ•°çš„é€‰æ‹©ä»¥åŠè®­ç»ƒæ•°æ®é›†çš„å¤§å°å’Œç»„æˆã€‚ä»”ç»†è°ƒæ•´å’Œå®éªŒè¿™äº›è®¾ç½®ä»¥å®ç°ç»™å®šä»»åŠ¡çš„æœ€ä½³æ€§èƒ½æ˜¯éå¸¸é‡è¦çš„ã€‚

| é”®                | å€¼       | æè¿°                                                         |
| :---------------- | :------- | :----------------------------------------------------------- |
| `model`           | `None`   | æ¨¡å‹æ–‡ä»¶è·¯å¾„ï¼Œä¾‹å¦‚ yolov8n.pt, yolov8n.yaml                  |
| `data`            | `None`   | æ•°æ®æ–‡ä»¶è·¯å¾„ï¼Œä¾‹å¦‚ coco128.yaml                              |
| `epochs`          | `100`    | è®­ç»ƒçš„è½®æ¬¡æ•°é‡                                               |
| `time`            | `None`   | è®­ç»ƒçš„æ—¶é•¿ï¼ˆæµ®ç‚¹æ•°ï¼‰ï¼Œå¦‚æœæä¾›å°±ä¼šè¦†ç›–epochså‚æ•°             |
| `patience`        | `50`     | æ—©åœè®­ç»ƒçš„ç­‰å¾…è½®æ¬¡                                           |
| `batch`           | `16`     | æ¯æ‰¹å›¾åƒæ•°é‡ï¼ˆ-1ä¸ºè‡ªåŠ¨æ‰¹å¤§å°ï¼‰                               |
| `imgsz`           | `640`    | è¾“å…¥å›¾åƒçš„å¤§å°ï¼Œä»¥æ•´æ•°è¡¨ç¤º                                   |
| `save`            | `True`   | ä¿å­˜è®­ç»ƒæ£€æŸ¥ç‚¹å’Œé¢„æµ‹ç»“æœ                                     |
| `save_period`     | `-1`     | æ¯xè½®æ¬¡ä¿å­˜æ£€æŸ¥ç‚¹ï¼ˆå¦‚æœ<1åˆ™ç¦ç”¨ï¼‰                            |
| `cache`           | `False`  | True/ram, disk æˆ– Falseã€‚ä½¿ç”¨ç¼“å­˜åŠ è½½æ•°æ®                    |
| `device`          | `None`   | è¿è¡Œè®¾å¤‡ï¼Œä¾‹å¦‚ cuda device=0 æˆ– device=0,1,2,3 æˆ– device=cpu |
| `workers`         | `8`      | æ•°æ®åŠ è½½çš„å·¥ä½œçº¿ç¨‹æ•°ï¼ˆå¦‚æœDDPåˆ™ä¸ºæ¯ä¸ªRANKï¼‰                  |
| `project`         | `None`   | é¡¹ç›®åç§°                                                     |
| `name`            | `None`   | å®éªŒåç§°                                                     |
| `exist_ok`        | `False`  | æ˜¯å¦è¦†ç›–ç°æœ‰å®éªŒ                                             |
| `pretrained`      | `True`   | (bool æˆ– str) æ˜¯å¦ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼ˆboolï¼‰æˆ–ä»ä¸­åŠ è½½æƒé‡çš„æ¨¡å‹ï¼ˆstrï¼‰ |
| `optimizer`       | `'auto'` | ä½¿ç”¨çš„ä¼˜åŒ–å™¨ï¼Œé€‰æ‹©èŒƒå›´=[SGD, Adam, Adamax, AdamW, NAdam, RAdam, RMSProp, auto] |
| `verbose`         | `False`  | æ˜¯å¦æ‰“å°è¯¦ç»†è¾“å‡º                                             |
| `seed`            | `0`      | éšæœºç§å­ï¼Œç”¨äºå¯é‡å¤æ€§                                       |
| `deterministic`   | `True`   | æ˜¯å¦å¯ç”¨ç¡®å®šæ€§æ¨¡å¼                                           |
| `single_cls`      | `False`  | å°†å¤šç±»æ•°æ®ä½œä¸ºå•ç±»è®­ç»ƒ                                       |
| `rect`            | `False`  | çŸ©å½¢è®­ç»ƒï¼Œæ¯æ‰¹ä¸ºæœ€å°å¡«å……æ•´åˆ                                 |
| `cos_lr`          | `False`  | ä½¿ç”¨ä½™å¼¦å­¦ä¹ ç‡è°ƒåº¦å™¨                                         |
| `close_mosaic`    | `10`     | (int) æœ€åè½®æ¬¡ç¦ç”¨é©¬èµ›å…‹å¢å¼ºï¼ˆ0ä¸ºç¦ç”¨ï¼‰                      |
| `resume`          | `False`  | ä»æœ€åæ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ                                         |
| `amp`             | `True`   | è‡ªåŠ¨æ··åˆç²¾åº¦ï¼ˆAMPï¼‰è®­ç»ƒï¼Œé€‰æ‹©èŒƒå›´=[True, False]              |
| `fraction`        | `1.0`    | è®­ç»ƒçš„æ•°æ®é›†æ¯”ä¾‹ï¼ˆé»˜è®¤ä¸º1.0ï¼Œå³è®­ç»ƒé›†ä¸­çš„æ‰€æœ‰å›¾åƒï¼‰          |
| `profile`         | `False`  | åœ¨è®­ç»ƒæœŸé—´ä¸ºè®°å½•å™¨åˆ†æONNXå’ŒTensorRTé€Ÿåº¦                     |
| `freeze`          | `None`   | (int æˆ– list, å¯é€‰) åœ¨è®­ç»ƒæœŸé—´å†»ç»“å‰nå±‚ï¼Œæˆ–å†»ç»“å±‚ç´¢å¼•åˆ—è¡¨    |
| `lr0`             | `0.01`   | åˆå§‹å­¦ä¹ ç‡ï¼ˆä¾‹å¦‚ SGD=1E-2, Adam=1E-3ï¼‰                       |
| `lrf`             | `0.01`   | æœ€ç»ˆå­¦ä¹ ç‡ (lr0 * lrf)                                       |
| `momentum`        | `0.937`  | SGDåŠ¨é‡/Adam beta1                                           |
| `weight_decay`    | `0.0005` | ä¼˜åŒ–å™¨æƒé‡è¡°å‡5e-4                                           |
| `warmup_epochs`   | `3.0`    | çƒ­èº«è½®æ¬¡ï¼ˆå°æ•°okï¼‰                                           |
| `warmup_momentum` | `0.8`    | çƒ­èº«åˆå§‹åŠ¨é‡                                                 |
| `warmup_bias_lr`  | `0.1`    | çƒ­èº«åˆå§‹åå·®lr                                               |
| `box`             | `7.5`    | æ¡†æŸå¤±å¢ç›Š                                                   |
| `cls`             | `0.5`    | clsæŸå¤±å¢ç›Šï¼ˆæ ¹æ®åƒç´ ç¼©æ”¾ï¼‰                                  |
| `dfl`             | `1.5`    | dflæŸå¤±å¢ç›Š                                                  |
| `pose`            | `12.0`   | å§¿æ€æŸå¤±å¢ç›Šï¼ˆä»…é™å§¿æ€ï¼‰                                     |
| `kobj`            | `2.0`    | å…³é”®ç‚¹objæŸå¤±å¢ç›Šï¼ˆä»…é™å§¿æ€ï¼‰                                |
| `label_smoothing` | `0.0`    | æ ‡ç­¾å¹³æ»‘ï¼ˆå°æ•°ï¼‰                                             |
| `nbs`             | `64`     | æ ‡ç§°æ‰¹å¤§å°                                                   |
| `overlap_mask`    | `True`   | è®­ç»ƒæœŸé—´æ©ç åº”é‡å ï¼ˆä»…é™åˆ†å‰²è®­ç»ƒï¼‰                           |
| `mask_ratio`      | `4`      | æ©ç é™é‡‡æ ·æ¯”ç‡ï¼ˆä»…é™åˆ†å‰²è®­ç»ƒï¼‰                               |
| `dropout`         | `0.0`    | ä½¿ç”¨dropoutæ­£åˆ™åŒ–ï¼ˆä»…é™åˆ†ç±»è®­ç»ƒï¼‰                            |
| `val`             | `True`   | è®­ç»ƒæœŸé—´éªŒè¯/æµ‹è¯•                                            |

>`rect = True` ä½¿ç”¨é•¿æ–¹å½¢è®­ç»ƒ
>
>Setting "rect"=True allows you to train using rectangular images, not necessarily square ones. This allows for more efficient use of GPU memory as there's less need for padding spatial dimensions.
>
>[Custom input size: letterbox vs resizing Â· Issue #11350 ](https://github.com/ultralytics/yolov5/issues/11350)
>
>[About the rectangle training Â· Issue #4819](https://github.com/ultralytics/ultralytics/issues/4819)

## example



```sh
# Build a new model from YAML and start training from scratch
yolo detect train data=coco128.yaml model=yolov8n.yaml epochs=100 imgsz=640

# Start training from a pretrained *.pt model
yolo detect train data=coco128.yaml model=yolov8n.pt epochs=100 imgsz=640

# Build a new model from YAML, transfer pretrained weights to it and start training
yolo detect train data=coco128.yaml model=yolov8n.yaml pretrained=yolov8n.pt epochs=100 imgsz=640
```

> `Multi-GPU Training`

```sh
# Start training from a pretrained *.pt model using GPUs 0 and 1
yolo detect train data=coco128.yaml model=yolov8n.pt epochs=100 imgsz=640 device=0,1
```

> `auto optimizer`

```sh
yolo task=detect mode=train imgsz=640 batch=-1 workers=8 epochs=300 patience=0 close_mosaic=10 fraction=1.0 cos_lr=True device=0 model=ultralytics/cfg/models/v8/yolov8n.yaml pretrained=weights/yolov8n.pt data=ultralytics/datasets/coco128.yaml

#                                                                                                                                modelå¯ä»¥ç›´æ¥è®¾ç½®ä¸ºpt
yolo task=detect mode=train imgsz=640 batch=-1 workers=8 epochs=300 patience=0 close_mosaic=10 fraction=1.0 cos_lr=True device=0 model=weights/yolov8n.pt data=ultralytics/cfg/datasets/coco128.yaml

#                                                        rtdetr è®­ç»ƒè½®æ•°æ›´å°‘
yolo task=detect mode=train imgsz=640 batch=-1 workers=8 epochs=100 patience=0 close_mosaic=10 fraction=1.0 cos_lr=True device=0 model=ultralytics/cfg/models/rt-detr/rtdetr-x.yaml pretrained=weights/rtdetr-x.pt data=ultralytics/cfg/datasets/coco128.yaml

#                                                        rtdetr è®­ç»ƒè½®æ•°æ›´å°‘                                                       modelå¯ä»¥ç›´æ¥è®¾ç½®ä¸ºpt
yolo task=detect mode=train imgsz=640 batch=-1 workers=8 epochs=100 patience=0 close_mosaic=10 fraction=1.0 cos_lr=True device=0 model=weights/rtdetr-x.pt data=ultralytics/cfg/datasets/coco128.yaml
```

> `SGD`

```sh
yolo task=detect mode=train imgsz=640 batch=-1 workers=8 epochs=300 patience=0 close_mosaic=10 fraction=1.0 optimizer=SGD lr0=0.01 cos_lr=True device=0 model=ultralytics/cfg/models/v8/yolov8n.yaml pretrained=weights/yolov8n.pt data=ultralytics/cfg/datasets/coco128.yaml

#                                                                                                                                                       modelå¯ä»¥ç›´æ¥è®¾ç½®ä¸ºpt
yolo task=detect mode=train imgsz=640 batch=-1 workers=8 epochs=300 patience=0 close_mosaic=10 fraction=1.0 optimizer=SGD lr0=0.01 cos_lr=True device=0 model=weights/yolov8n.pt data=ultralytics/cfg/datasets/coco128.yaml
```

> `Adam`

```sh
yolo task=detect mode=train imgsz=640 batch=-1 workers=8 epochs=300 patience=0 close_mosaic=10 fraction=1.0 optimizer=AdamW lr0=0.001 cos_lr=True device=0 model=ultralytics/cfg/models/v8/yolov8n.yaml pretrained=weights/yolov8n.pt data=ultralytics/cfg/datasets/coco128.yaml

#                                                                                                                                                          modelå¯ä»¥ç›´æ¥è®¾ç½®ä¸ºpt
yolo task=detect mode=train imgsz=640 batch=-1 workers=8 epochs=300 patience=0 close_mosaic=10 fraction=1.0 optimizer=AdamW lr0=0.001 cos_lr=True device=0 model=weights/yolov8n.pt data=ultralytics/cfg/datasets/coco128.yaml
```

> `resume`

```sh
#                                                                                                                                model=æœ€åçš„pt
yolo task=detect mode=train imgsz=640 batch=-1 workers=8 epochs=300 patience=0 close_mosaic=10 fraction=1.0 cos_lr=True device=0 model=weights/last.pt data=ultralytics/cfg/datasets/coco128.yaml resume=True exist_ok=True
```

## **ä¸éœ€è¦åœ¨æ¨¡å‹é…ç½®ä¸­æ˜¾ç¤ºæ›´æ”¹ç±»åˆ«æ•°**

> ä¼šè‡ªåŠ¨å°†ncè°ƒæ•´ä¸ºæ•°æ®é›†çš„ç±»åˆ«æ•°é‡

```sh
> yolo task=detect mode=train imgsz=640 batch=-1 epochs=300 optimizer=SGD lr0=0.01 cos_lr=True device=0 pretrained=weights/yolov8n.pt model=ultralytics/models/v8/yolov8n.yaml data=ultralytics/datasets/classes20.yaml

                   from  n    params  module                                       arguments
  0                  -1  1       464  ultralytics.nn.modules.Conv                  [3, 16, 3, 2]
  1                  -1  1      4672  ultralytics.nn.modules.Conv                  [16, 32, 3, 2]
  2                  -1  1      7360  ultralytics.nn.modules.C2f                   [32, 32, 1, True]
  3                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]
  4                  -1  2     49664  ultralytics.nn.modules.C2f                   [64, 64, 2, True]
  5                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]
  6                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]
  7                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]
  8                  -1  1    460288  ultralytics.nn.modules.C2f                   [256, 256, 1, True]
  9                  -1  1    164608  ultralytics.nn.modules.SPPF                  [256, 256, 5]
 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']
 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]
 12                  -1  1    148224  ultralytics.nn.modules.C2f                   [384, 128, 1]
 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']
 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]
 15                  -1  1     37248  ultralytics.nn.modules.C2f                   [192, 64, 1]
 16                  -1  1     36992  ultralytics.nn.modules.Conv                  [64, 64, 3, 2]
 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]
 18                  -1  1    123648  ultralytics.nn.modules.C2f                   [192, 128, 1]
 19                  -1  1    147712  ultralytics.nn.modules.Conv                  [128, 128, 3, 2]
 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]
 21                  -1  1    493056  ultralytics.nn.modules.C2f                   [384, 256, 1]
 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.Detect                [80, [64, 128, 256]]
yolov8n summary: 225 layers, 3157200 parameters, 3157184 gradients, 8.9 GFLOPs

Transferred 355/355 items from pretrained weights
Ultralytics YOLOv8.0.58  Python-3.10.9 torch-2.0.0+cu118 CUDA:0 (NVIDIA GeForce GTX 1080 Ti, 11264MiB)
yolo\engine\trainer: task=detect, mode=train, model=ultralytics/models/v8/yolov8n.yaml, data=ultralytics/datasets/classes20.yaml, epochs=300, patience=50, batch=-1, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=None, exist_ok=False, pretrained=weights/yolov8n.pt, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=True, close_mosaic=10, resume=False, amp=True, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, hide_labels=False, hide_conf=False, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=d:\code\ultralytics\runs\detect\train2
Overriding model.yaml nc=80 with nc=20		# è¿™é‡Œè‡ªåŠ¨è¦†ç›–äº†æ—§çš„ç±»åˆ«æ•°

                   from  n    params  module                                       arguments
  0                  -1  1       464  ultralytics.nn.modules.Conv                  [3, 16, 3, 2]
  1                  -1  1      4672  ultralytics.nn.modules.Conv                  [16, 32, 3, 2]
  2                  -1  1      7360  ultralytics.nn.modules.C2f                   [32, 32, 1, True]
  3                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]
  4                  -1  2     49664  ultralytics.nn.modules.C2f                   [64, 64, 2, True]
  5                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]
  6                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]
  7                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]
  8                  -1  1    460288  ultralytics.nn.modules.C2f                   [256, 256, 1, True]
  9                  -1  1    164608  ultralytics.nn.modules.SPPF                  [256, 256, 5]
 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']
 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]
 12                  -1  1    148224  ultralytics.nn.modules.C2f                   [384, 128, 1]
 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']
 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]
 15                  -1  1     37248  ultralytics.nn.modules.C2f                   [192, 64, 1]
 16                  -1  1     36992  ultralytics.nn.modules.Conv                  [64, 64, 3, 2]
 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]
 18                  -1  1    123648  ultralytics.nn.modules.C2f                   [192, 128, 1]
 19                  -1  1    147712  ultralytics.nn.modules.Conv                  [128, 128, 3, 2]
 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]
 21                  -1  1    493056  ultralytics.nn.modules.C2f                   [384, 256, 1]
 22        [15, 18, 21]  1    755212  ultralytics.nn.modules.Detect                [20, [64, 128, 256]]
yolov8n summary: 225 layers, 3014748 parameters, 3014732 gradients, 8.2 GFLOPs

Transferred 319/355 items from pretrained weights
TensorBoard: Start with 'tensorboard --logdir d:\code\ultralytics\runs\detect\train', view at http://localhost:6006/
AMP: running Automatic Mixed Precision (AMP) checks with yolov8n...
AMP: checks passed
AutoBatch: Computing optimal batch size for imgsz=640
AutoBatch: CUDA:0 (NVIDIA GeForce GTX 1080 Ti) 11.00G total, 0.10G reserved, 0.07G allocated, 10.83G free
      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output
     3014748       8.215         0.210         28.59         17.95        (1, 3, 640, 640)                    list
     3014748       16.43         0.296         13.96         21.27        (2, 3, 640, 640)                    list
     3014748       32.86         0.581         12.96         20.99        (4, 3, 640, 640)                    list
     3014748       65.72         1.065         20.27          28.6        (8, 3, 640, 640)                    list
     3014748       131.4         2.334         34.56         48.56       (16, 3, 640, 640)                    list
AutoBatch: Using batch-size 50 for CUDA:0 7.30G/11.00G (66%)
optimizer: SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.000390625), 63 bias
train: Scanning D:\code\datasets\classes20\labels\train.cache... 5266 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
val: Scanning D:\code\datasets\classes20\labels\val.cache... 586 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 586
Plotting labels to d:\code\ultralytics\runs\detect\train\labels.jpg...
Image sizes 640 train, 640 val
Using 8 dataloader workers
Logging results to d:\code\ultralytics\runs\detect\train
Starting training for 300 epochs...
```

> è‡ªåŠ¨è°ƒæ•´ `nc` çš„ä»£ç åœ¨ `ultralytics/nn/task.py`

```python
        ch = self.yaml['ch'] = self.yaml.get('ch', ch)  # input channels
        if nc and nc != self.yaml['nc']:    # ä½¿ç”¨data configä¸­çš„namesé•¿åº¦è¦†ç›–æ¨¡å‹é…ç½®æ–‡ä»¶ä¸­çš„ç±»åˆ«
            LOGGER.info(f"Overriding model.yaml nc={self.yaml['nc']} with nc={nc}")
            self.yaml['nc'] = nc  # override yaml value
```

## è®­ç»ƒæ—¶å‡ºç°çš„é—®é¢˜

### è®­ç»ƒ `obj_loss` å¢å¤§ | reduce FPs | è§£å†³ç‰¹æ®Šåœºæ™¯æ¨¡å‹æ‹æ‘„æ—¥å¸¸ç›®æ ‡çš„FPæ•°é‡è¿‡å¤š

> [how to use Background images in training? Â· Issue #2844 Â· ultralytics/yolov5 (github.com)](https://github.com/ultralytics/yolov5/issues/2844)
>
> åœ¨å›¾ç‰‡è®­ç»ƒæ–‡ä»¶å¤¹ `images/train` ä¸­æ·»åŠ èƒŒæ™¯å›¾ç‰‡æ–‡ä»¶ï¼Œæ¯”å¦‚cocoæˆ–è€…vocæ•°æ®é›†çš„ä¸€äº›ç…§ç‰‡
>
> ä¸éœ€è¦æ·»åŠ ç©ºç™½label txtæ–‡ä»¶ï¼Œæ·»åŠ äº†ä¹Ÿä¸ä¼šå‡ºé”™
>
> `(if no objects in image, no `*.txt` file is required).`
>
> [ç›®æ ‡æ£€æµ‹ï¼ˆé™ä½è¯¯æ£€æµ‹ç‡åŠå°ç›®æ ‡æ£€æµ‹ç³»åˆ—ç¬”è®°ï¼‰](https://blog.csdn.net/weixin_44836143/article/details/105952819)

```sh
train: Scanning D:\code\datasets\classes20\labels\train... 5266 images, 1000 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ|
train: New cache created: D:\code\datasets\classes20\labels\train.cache
val: Scanning D:\code\datasets\classes20\labels\val... 586 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ|
val: New cache created: D:\code\datasets\classes20\labels\val.cache
```



# [éªŒè¯](https://docs.ultralytics.com/zh/modes/val/)

## Val æ¨¡å¼çš„ä¸»è¦ç‰¹ç‚¹

ä»¥ä¸‹æ˜¯ YOLOv8 çš„ Val æ¨¡å¼æä¾›çš„æ˜¾è‘—åŠŸèƒ½ï¼š

- **è‡ªåŠ¨åŒ–è®¾ç½®ï¼š** æ¨¡å‹è®°ä½å…¶è®­ç»ƒé…ç½®ï¼Œä»¥ä¾¿ç›´æ¥è¿›è¡ŒéªŒè¯ã€‚
- **å¤šæŒ‡æ ‡æ”¯æŒï¼š** æ ¹æ®ä¸€ç³»åˆ—å‡†ç¡®åº¦æŒ‡æ ‡è¯„ä¼°æ‚¨çš„æ¨¡å‹ã€‚
- **CLI å’Œ Python APIï¼š** æ ¹æ®æ‚¨çš„éªŒè¯åå¥½é€‰æ‹©å‘½ä»¤è¡Œç•Œé¢æˆ– Python APIã€‚
- **æ•°æ®å…¼å®¹æ€§ï¼š** ä¸è®­ç»ƒé˜¶æ®µä½¿ç”¨çš„æ•°æ®é›†ä»¥åŠè‡ªå®šä¹‰æ•°æ®é›†æ— ç¼åä½œã€‚

## ä½¿ç”¨ç¤ºä¾‹

åœ¨ COCO128 æ•°æ®é›†ä¸ŠéªŒè¯è®­ç»ƒè¿‡çš„ YOLOv8n æ¨¡å‹çš„å‡†ç¡®æ€§ã€‚ç”±äº `model` ä¿ç•™äº†å…¶è®­ç»ƒçš„ `data` å’Œå‚æ•°ä½œä¸ºæ¨¡å‹å±æ€§ï¼Œå› æ­¤æ— éœ€ä¼ é€’ä»»ä½•å‚æ•°ã€‚æœ‰å…³å®Œæ•´çš„å¯¼å‡ºå‚æ•°åˆ—è¡¨ï¼Œè¯·å‚é˜…ä¸‹é¢çš„å‚æ•°éƒ¨åˆ†ã€‚

> python

```python
from ultralytics import YOLO

# åŠ è½½æ¨¡å‹
model = YOLO('yolov8n.pt')  # åŠ è½½å®˜æ–¹æ¨¡å‹
model = YOLO('path/to/best.pt')  # åŠ è½½è‡ªå®šä¹‰æ¨¡å‹

# éªŒè¯æ¨¡å‹
metrics = model.val()  # æ— éœ€å‚æ•°ï¼Œæ•°æ®é›†å’Œè®¾ç½®è®°å¿†
metrics.box.map    # map50-95
metrics.box.map50  # map50
metrics.box.map75  # map75
metrics.box.maps   # åŒ…å«æ¯ä¸ªç±»åˆ«çš„map50-95åˆ—è¡¨
```

> cli

```sh
yolo detect val model=yolov8n.pt  # éªŒè¯å®˜æ–¹æ¨¡å‹
yolo detect val model=path/to/best.pt  # éªŒè¯è‡ªå®šä¹‰æ¨¡å‹
```

## å‚æ•°

YOLO æ¨¡å‹çš„éªŒè¯è®¾ç½®æ˜¯æŒ‡ç”¨äºè¯„ä¼°æ¨¡å‹åœ¨éªŒè¯æ•°æ®é›†ä¸Šæ€§èƒ½çš„å„ç§è¶…å‚æ•°å’Œé…ç½®ã€‚è¿™äº›è®¾ç½®ä¼šå½±å“æ¨¡å‹çš„æ€§èƒ½ã€é€Ÿåº¦å’Œå‡†ç¡®æ€§ã€‚ä¸€äº›å¸¸è§çš„ YOLO éªŒè¯è®¾ç½®åŒ…æ‹¬æ‰¹å¤„ç†å¤§å°ã€åœ¨è®­ç»ƒæœŸé—´éªŒè¯é¢‘ç‡ä»¥åŠç”¨äºè¯„ä¼°æ¨¡å‹æ€§èƒ½çš„æŒ‡æ ‡ã€‚å…¶ä»–å¯èƒ½å½±å“éªŒè¯è¿‡ç¨‹çš„å› ç´ åŒ…æ‹¬éªŒè¯æ•°æ®é›†çš„å¤§å°å’Œç»„æˆä»¥åŠæ¨¡å‹ç”¨äºç‰¹å®šä»»åŠ¡çš„ç‰¹æ€§ã€‚ä»”ç»†è°ƒæ•´å’Œå®éªŒè¿™äº›è®¾ç½®å¾ˆé‡è¦ï¼Œä»¥ç¡®ä¿æ¨¡å‹åœ¨éªŒè¯æ•°æ®é›†ä¸Šè¡¨ç°è‰¯å¥½å¹¶ä¸”æ£€æµ‹å’Œé¢„é˜²è¿‡æ‹Ÿåˆã€‚

| é”®            | å€¼      | æè¿°                                                   |
| :------------ | :------ | :----------------------------------------------------- |
| `data`        | `None`  | æ•°æ®æ–‡ä»¶çš„è·¯å¾„ï¼Œä¾‹å¦‚ coco128.yaml                      |
| `imgsz`       | `640`   | è¾“å…¥å›¾åƒçš„å¤§å°ï¼Œä»¥æ•´æ•°è¡¨ç¤º                             |
| `batch`       | `16`    | æ¯æ‰¹å›¾åƒçš„æ•°é‡ï¼ˆAutoBatch ä¸º -1ï¼‰                      |
| `save_json`   | `False` | å°†ç»“æœä¿å­˜è‡³ JSON æ–‡ä»¶                                 |
| `save_hybrid` | `False` | ä¿å­˜æ··åˆç‰ˆæœ¬çš„æ ‡ç­¾ï¼ˆæ ‡ç­¾ + é¢å¤–é¢„æµ‹ï¼‰                  |
| `conf`        | `0.001` | ç”¨äºæ£€æµ‹çš„å¯¹è±¡ç½®ä¿¡åº¦é˜ˆå€¼                               |
| `iou`         | `0.6`   | NMSï¼ˆéæå¤§æŠ‘åˆ¶ï¼‰ç”¨çš„äº¤å¹¶æ¯”ï¼ˆIoUï¼‰é˜ˆå€¼                 |
| `max_det`     | `300`   | æ¯å¼ å›¾åƒçš„æœ€å¤§æ£€æµ‹æ•°é‡                                 |
| `half`        | `True`  | ä½¿ç”¨åŠç²¾åº¦ï¼ˆFP16ï¼‰                                     |
| `device`      | `None`  | è¿è¡Œæ‰€ç”¨çš„è®¾å¤‡ï¼Œä¾‹å¦‚ cuda device=0/1/2/3 æˆ– device=cpu |
| `dnn`         | `False` | ä½¿ç”¨ OpenCV DNN è¿›è¡Œ ONNX æ¨ç†                         |
| `plots`       | `False` | åœ¨è®­ç»ƒæœŸé—´æ˜¾ç¤ºå›¾è¡¨                                     |
| `rect`        | `False` | çŸ©å½¢éªŒè¯ï¼Œæ¯æ‰¹å›¾åƒä¸ºäº†æœ€å°å¡«å……æ•´é½æ’åˆ—                 |
| `split`       | `val`   | ç”¨äºéªŒè¯çš„æ•°æ®é›†åˆ†å‰²ï¼Œä¾‹å¦‚ 'val'ã€'test' æˆ– 'train'    |

> example

```sh
yolo detect val model=yolov8n.pt  # val official model
yolo detect val model=path/to/best.pt  # val custom model
```

### default confidence threshold = 0.001

> [mAP bug at higher --conf Â· Issue #1466 Â· ultralytics/yolov5](https://github.com/ultralytics/yolov5/issues/1466)
>
> [Why does the confidence threshold of 0.001 in val.py result in good results? Â· Issue #11745 Â· ultralytics/yolov5](https://github.com/ultralytics/yolov5/issues/11745)

### éªŒè¯æ¨¡å‹åœ¨è‡ªå®šä¹‰æ•°æ®é›†ä¸Šçš„æ•ˆæœ ç²¾åº¦0.995

> https://www.jianshu.com/p/cfb01add61bd#1684051613808
>
> https://github.com/ultralytics/yolov5/issues/5508
>
> https://github.com/ultralytics/yolov5/issues/1563
>
> https://github.com/ultralytics/yolov5/pull/1646
>
> `savehybrid` ä¼šåˆå¹¶å·²çŸ¥çš„labelsï¼Œå¯¼è‡´å¾—åˆ†å¾ˆé«˜

## torch

```sh
yolo task=detect mode=val imgsz=640 save_json=True save_txt=True save_conf=True conf=0.25 iou=0.6 data=ultralytics/cfg/datasets/coco128.yaml model=weights/yolov8n.pt device=0
```

## torchscript

```sh
yolo task=detect mode=val imgsz=640 save_json=True save_txt=True save_conf=True conf=0.25 iou=0.6 data=ultralytics/cfg/datasets/coco128.yaml model=weights/yolov8n.torchscript device=0
```

## onnx

> æ³¨æ„:
>
> `onnxruntime` å’Œ `onnxruntime-gpu` ä¸è¦åŒæ—¶å®‰è£…ï¼Œå¦åˆ™ä½¿ç”¨ `gpu` æ¨ç†æ—¶é€Ÿåº¦ä¼šå¾ˆæ…¢ï¼Œå¦‚æœåŒæ—¶å®‰è£…äº†2ä¸ªåŒ…ï¼Œè¦å…¨éƒ¨å¸è½½ï¼Œå†å®‰è£… `onnxruntime-gpu` æ‰èƒ½ä½¿ç”¨gpuæ¨ç†ï¼Œå¦åˆ™gpué€Ÿåº¦ä¼šå¾ˆæ…¢

```sh
yolo task=detect mode=val imgsz=640 save_json=True save_txt=True save_conf=True conf=0.25 iou=0.6 data=ultralytics/cfg/datasets/coco128.yaml model=weights/yolov8n.onnx device=0
```

## openvino

> æ³¨æ„ï¼šopenvinoæ²¡æ³•ä½¿ç”¨cudaï¼Œä½†æ˜¯ä½¿ç”¨ --device 0 ä¼šæé«˜æ¨ç†é€Ÿåº¦

```sh
yolo task=detect mode=val imgsz=640 save_json=True save_txt=True save_conf=True conf=0.25 iou=0.6 data=ultralytics/cfg/datasets/coco128.yaml model=weights/yolov8n_openvnio_model device=cpu
```

## tensorrt

```sh
yolo task=detect mode=val imgsz=640 save_json=True save_txt=True save_conf=True conf=0.25 iou=0.6 data=ultralytics/cfg/datasets/coco128.yaml model=weights/yolov8n.onnx device=0 half=True
```

# [é¢„æµ‹](https://docs.ultralytics.com/zh/modes/predict/)

## é¢„æµ‹æ¨¡å¼çš„å…³é”®ç‰¹æ€§

YOLOv8 çš„é¢„æµ‹æ¨¡å¼è¢«è®¾è®¡ä¸ºå¼ºå¤§ä¸”å¤šåŠŸèƒ½ï¼ŒåŒ…æ‹¬ä»¥ä¸‹ç‰¹æ€§ï¼š

- **å…¼å®¹å¤šä¸ªæ•°æ®æ¥æºï¼š** æ— è®ºæ‚¨çš„æ•°æ®æ˜¯å•ç‹¬å›¾ç‰‡ï¼Œå›¾ç‰‡é›†åˆï¼Œè§†é¢‘æ–‡ä»¶ï¼Œè¿˜æ˜¯å®æ—¶è§†é¢‘æµï¼Œé¢„æµ‹æ¨¡å¼éƒ½èƒ½èƒœä»»ã€‚
- **æµå¼æ¨¡å¼ï¼š** ä½¿ç”¨æµå¼åŠŸèƒ½ç”Ÿæˆä¸€ä¸ªå†…å­˜é«˜æ•ˆçš„ `Results` å¯¹è±¡ç”Ÿæˆå™¨ã€‚åœ¨è°ƒç”¨é¢„æµ‹å™¨æ—¶ï¼Œé€šè¿‡è®¾ç½® `stream=True` æ¥å¯ç”¨æ­¤åŠŸèƒ½ã€‚
- **æ‰¹å¤„ç†ï¼š** èƒ½å¤Ÿåœ¨å•ä¸ªæ‰¹æ¬¡ä¸­å¤„ç†å¤šä¸ªå›¾ç‰‡æˆ–è§†é¢‘å¸§ï¼Œè¿›ä¸€æ­¥åŠ å¿«æ¨ç†æ—¶é—´ã€‚
- **æ˜“äºé›†æˆï¼š** ç”±äºå…¶çµæ´»çš„ APIï¼Œæ˜“äºä¸ç°æœ‰æ•°æ®ç®¡é“å’Œå…¶ä»–è½¯ä»¶ç»„ä»¶é›†æˆã€‚

## ä½¿ç”¨ç¤ºä¾‹

Ultralytics YOLO æ¨¡å‹åœ¨è¿›è¡Œæ¨ç†æ—¶è¿”å›ä¸€ä¸ª Python `Results` å¯¹è±¡åˆ—è¡¨ï¼Œæˆ–è€…å½“ä¼ å…¥ `stream=True` æ—¶ï¼Œè¿”å›ä¸€ä¸ªå†…å­˜é«˜æ•ˆçš„ Python `Results` å¯¹è±¡ç”Ÿæˆå™¨ï¼š

> ä½¿ç”¨ `stream=False` è¿”å›åˆ—è¡¨

```python
from ultralytics import YOLO

# åŠ è½½æ¨¡å‹
model = YOLO('yolov8n.pt')  # é¢„è®­ç»ƒçš„ YOLOv8n æ¨¡å‹

# åœ¨å›¾ç‰‡åˆ—è¡¨ä¸Šè¿è¡Œæ‰¹é‡æ¨ç†
results = model(['im1.jpg', 'im2.jpg'])  # è¿”å› Results å¯¹è±¡åˆ—è¡¨

# å¤„ç†ç»“æœåˆ—è¡¨
for result in results:
    boxes = result.boxes  # è¾¹ç•Œæ¡†è¾“å‡ºçš„ Boxes å¯¹è±¡
    masks = result.masks  # åˆ†å‰²æ©ç è¾“å‡ºçš„ Masks å¯¹è±¡
    keypoints = result.keypoints  # å§¿æ€è¾“å‡ºçš„ Keypoints å¯¹è±¡
    probs = result.probs  # åˆ†ç±»è¾“å‡ºçš„ Probs å¯¹è±¡
```

> ä½¿ç”¨ `stream=True` è¿”å›ç”Ÿæˆå™¨

```python
from ultralytics import YOLO

# åŠ è½½æ¨¡å‹
model = YOLO('yolov8n.pt')  # é¢„è®­ç»ƒçš„ YOLOv8n æ¨¡å‹

# åœ¨å›¾ç‰‡åˆ—è¡¨ä¸Šè¿è¡Œæ‰¹é‡æ¨ç†
results = model(['im1.jpg', 'im2.jpg'], stream=True)  # è¿”å› Results å¯¹è±¡ç”Ÿæˆå™¨

# å¤„ç†ç»“æœç”Ÿæˆå™¨
for result in results:
    boxes = result.boxes  # è¾¹ç•Œæ¡†è¾“å‡ºçš„ Boxes å¯¹è±¡
    masks = result.masks  # åˆ†å‰²æ©ç è¾“å‡ºçš„ Masks å¯¹è±¡
    keypoints = result.keypoints  # å§¿æ€è¾“å‡ºçš„ Keypoints å¯¹è±¡
    probs = result.probs  # åˆ†ç±»è¾“å‡ºçš„ Probs å¯¹è±¡
```

## æ¨ç†æ¥æº

YOLOv8 å¯ä»¥å¤„ç†æ¨ç†è¾“å…¥çš„ä¸åŒç±»å‹ï¼Œå¦‚ä¸‹è¡¨æ‰€ç¤ºã€‚æ¥æºåŒ…æ‹¬é™æ€å›¾åƒã€è§†é¢‘æµå’Œå„ç§æ•°æ®æ ¼å¼ã€‚è¡¨æ ¼è¿˜è¡¨ç¤ºäº†æ¯ç§æ¥æºæ˜¯å¦å¯ä»¥åœ¨æµå¼æ¨¡å¼ä¸‹ä½¿ç”¨ï¼Œä½¿ç”¨å‚æ•° `stream=True` âœ…ã€‚æµå¼æ¨¡å¼å¯¹äºå¤„ç†è§†é¢‘æˆ–å®æ—¶æµéå¸¸æœ‰åˆ©ï¼Œå› ä¸ºå®ƒåˆ›å»ºäº†ç»“æœçš„ç”Ÿæˆå™¨ï¼Œè€Œä¸æ˜¯å°†æ‰€æœ‰å¸§åŠ è½½åˆ°å†…å­˜ã€‚

> ä½¿ç”¨ `stream=True` å¤„ç†é•¿è§†é¢‘æˆ–å¤§å‹æ•°æ®é›†æ¥é«˜æ•ˆåœ°ç®¡ç†å†…å­˜ã€‚å½“ `stream=False` æ—¶ï¼Œæ‰€æœ‰å¸§æˆ–æ•°æ®ç‚¹çš„ç»“æœéƒ½å°†å­˜å‚¨åœ¨å†…å­˜ä¸­ï¼Œè¿™å¯èƒ½å¾ˆå¿«å¯¼è‡´å†…å­˜ä¸è¶³é”™è¯¯ã€‚ç›¸å¯¹åœ°ï¼Œ`stream=True` ä½¿ç”¨ç”Ÿæˆå™¨ï¼Œåªä¿ç•™å½“å‰å¸§æˆ–æ•°æ®ç‚¹çš„ç»“æœåœ¨å†…å­˜ä¸­ï¼Œæ˜¾è‘—å‡å°‘äº†å†…å­˜æ¶ˆè€—ï¼Œé˜²æ­¢å†…å­˜ä¸è¶³é—®é¢˜ã€‚

| æ¥æº       | å‚æ•°                                       | ç±»å‹            | å¤‡æ³¨                                                         |
| :--------- | :----------------------------------------- | :-------------- | :----------------------------------------------------------- |
| å›¾åƒ       | `'image.jpg'`                              | `str` æˆ– `Path` | å•ä¸ªå›¾åƒæ–‡ä»¶ã€‚                                               |
| URL        | `'https://ultralytics.com/images/bus.jpg'` | `str`           | å›¾åƒçš„ URL åœ°å€ã€‚                                            |
| æˆªå±       | `'screen'`                                 | `str`           | æˆªå–å±å¹•å›¾åƒã€‚                                               |
| PIL        | `Image.open('im.jpg')`                     | `PIL.Image`     | RGB é€šé“çš„ HWC æ ¼å¼å›¾åƒã€‚                                    |
| OpenCV     | `cv2.imread('im.jpg')`                     | `np.ndarray`    | BGR é€šé“çš„ HWC æ ¼å¼å›¾åƒ `uint8 (0-255)`ã€‚                    |
| numpy      | `np.zeros((640,1280,3))`                   | `np.ndarray`    | BGR é€šé“çš„ HWC æ ¼å¼å›¾åƒ `uint8 (0-255)`ã€‚                    |
| torch      | `torch.zeros(16,3,320,640)`                | `torch.Tensor`  | RGB é€šé“çš„ BCHW æ ¼å¼å›¾åƒ `float32 (0.0-1.0)`ã€‚               |
| CSV        | `'sources.csv'`                            | `str` æˆ– `Path` | åŒ…å«å›¾åƒã€è§†é¢‘æˆ–ç›®å½•è·¯å¾„çš„ CSV æ–‡ä»¶ã€‚                        |
| è§†é¢‘ âœ…     | `'video.mp4'`                              | `str` æˆ– `Path` | å¦‚ MP4, AVI ç­‰æ ¼å¼çš„è§†é¢‘æ–‡ä»¶ã€‚                               |
| ç›®å½• âœ…     | `'path/'`                                  | `str` æˆ– `Path` | åŒ…å«å›¾åƒæˆ–è§†é¢‘æ–‡ä»¶çš„ç›®å½•è·¯å¾„ã€‚                               |
| é€šé…ç¬¦ âœ…   | `'path/*.jpg'`                             | `str`           | åŒ¹é…å¤šä¸ªæ–‡ä»¶çš„é€šé…ç¬¦æ¨¡å¼ã€‚ä½¿ç”¨ `*` å­—ç¬¦ä½œä¸ºé€šé…ç¬¦ã€‚          |
| YouTube âœ…  | `'https://youtu.be/LNwODJXcvt4'`           | `str`           | YouTube è§†é¢‘çš„ URL åœ°å€ã€‚                                    |
| æµåª’ä½“ âœ…   | `'rtsp://example.com/media.mp4'`           | `str`           | RTSP, RTMP, TCP æˆ– IP åœ°å€ç­‰æµåè®®çš„ URL åœ°å€ã€‚              |
| å¤šæµåª’ä½“ âœ… | `'list.streams'`                           | `str` æˆ– `Path` | ä¸€ä¸ªæµ URL æ¯è¡Œçš„ `*.streams` æ–‡æœ¬æ–‡ä»¶ï¼Œä¾‹å¦‚ 8 ä¸ªæµå°†ä»¥ 8 çš„æ‰¹å¤„ç†å¤§å°è¿è¡Œã€‚ |

## æ¨ç†å‚æ•°

`model.predict()` åœ¨æ¨ç†æ—¶æ¥å—å¤šä¸ªå‚æ•°ï¼Œå¯ä»¥ç”¨æ¥è¦†ç›–é»˜è®¤å€¼ï¼š

```python
from ultralytics import YOLO

# åŠ è½½é¢„è®­ç»ƒçš„YOLOv8næ¨¡å‹
model = YOLO('yolov8n.pt')

# åœ¨'bus.jpg'ä¸Šè¿è¡Œæ¨ç†ï¼Œå¹¶é™„åŠ å‚æ•°
model.predict('bus.jpg', save=True, imgsz=320, conf=0.5)
```

æ”¯æŒçš„æ‰€æœ‰å‚æ•°ï¼š

| åç§°            | ç±»å‹           | é»˜è®¤å€¼                 | æè¿°                                                 |
| :-------------- | :------------- | :--------------------- | :--------------------------------------------------- |
| `source`        | `str`          | `'ultralytics/assets'` | å›¾åƒæˆ–è§†é¢‘çš„æºç›®å½•                                   |
| `conf`          | `float`        | `0.25`                 | æ£€æµ‹å¯¹è±¡çš„ç½®ä¿¡åº¦é˜ˆå€¼                                 |
| `iou`           | `float`        | `0.7`                  | ç”¨äºNMSçš„äº¤å¹¶æ¯”ï¼ˆIoUï¼‰é˜ˆå€¼                           |
| `imgsz`         | `int or tuple` | `640`                  | å›¾åƒå¤§å°ï¼Œå¯ä»¥æ˜¯æ ‡é‡æˆ–ï¼ˆh, wï¼‰åˆ—è¡¨ï¼Œä¾‹å¦‚ï¼ˆ640, 480ï¼‰ |
| `half`          | `bool`         | `False`                | ä½¿ç”¨åŠç²¾åº¦ï¼ˆFP16ï¼‰                                   |
| `device`        | `None or str`  | `None`                 | è¿è¡Œè®¾å¤‡ï¼Œä¾‹å¦‚ cuda device=0/1/2/3 æˆ– device=cpu     |
| `show`          | `bool`         | `False`                | å¦‚æœå¯èƒ½ï¼Œæ˜¾ç¤ºç»“æœ                                   |
| `save`          | `bool`         | `False`                | ä¿å­˜å¸¦æœ‰ç»“æœçš„å›¾åƒ                                   |
| `save_txt`      | `bool`         | `False`                | å°†ç»“æœä¿å­˜ä¸º.txtæ–‡ä»¶                                 |
| `save_conf`     | `bool`         | `False`                | ä¿å­˜å¸¦æœ‰ç½®ä¿¡åº¦åˆ†æ•°çš„ç»“æœ                             |
| `save_crop`     | `bool`         | `False`                | ä¿å­˜å¸¦æœ‰ç»“æœçš„è£å‰ªå›¾åƒ                               |
| `show_labels`   | `bool`         | `True`                 | éšè—æ ‡ç­¾                                             |
| `show_conf`     | `bool`         | `True`                 | éšè—ç½®ä¿¡åº¦åˆ†æ•°                                       |
| `max_det`       | `int`          | `300`                  | æ¯å¼ å›¾åƒçš„æœ€å¤§æ£€æµ‹æ•°é‡                               |
| `vid_stride`    | `bool`         | `False`                | è§†é¢‘å¸§é€Ÿç‡è·³è·ƒ                                       |
| `stream_buffer` | `bool`         | `False`                | ç¼“å†²æ‰€æœ‰æµåª’ä½“å¸§ï¼ˆTrueï¼‰æˆ–è¿”å›æœ€æ–°å¸§ï¼ˆFalseï¼‰        |
| `line_width`    | `None or int`  | `None`                 | è¾¹æ¡†çº¿å®½åº¦ã€‚å¦‚æœä¸ºNoneï¼Œåˆ™æŒ‰å›¾åƒå¤§å°ç¼©æ”¾ã€‚           |
| `visualize`     | `bool`         | `False`                | å¯è§†åŒ–æ¨¡å‹ç‰¹å¾                                       |
| `augment`       | `bool`         | `False`                | åº”ç”¨å›¾åƒå¢å¼ºåˆ°é¢„æµ‹æº                                 |
| `agnostic_nms`  | `bool`         | `False`                | ç±»åˆ«ä¸æ•æ„Ÿçš„NMS                                      |
| `retina_masks`  | `bool`         | `False`                | ä½¿ç”¨é«˜åˆ†è¾¨ç‡åˆ†å‰²æ©ç                                  |
| `classes`       | `None or list` | `None`                 | æŒ‰ç±»åˆ«è¿‡æ»¤ç»“æœï¼Œä¾‹å¦‚ classes=0ï¼Œæˆ– classes=[0,2,3]   |
| `boxes`         | `bool`         | `True`                 | åœ¨åˆ†å‰²é¢„æµ‹ä¸­æ˜¾ç¤ºæ¡†                                   |

## torch

```sh
yolo task=detect mode=predict imgsz=640 save=True save_txt=True save_conf=True save_crop=True conf=0.25 iou=0.6 data=ultralytics/cfg/datasets/coco128.yaml model=weights/yolov8n.pt source=ultralytics/assets/bus.jpg device=0

yolo task=detect mode=predict imgsz=640 save=True save_txt=True save_conf=True save_crop=True conf=0.25 iou=0.6 data=ultralytics/cfg/datasets/coco128.yaml model=weights/yolov8n.pt source=../datasets/coco128/images/train2017 device=0
```

## torchscript

```sh
yolo task=detect mode=predict imgsz=640 save=True save_txt=True save_conf=True save_crop=True conf=0.25 iou=0.6 data=ultralytics/cfg/datasets/coco128.yaml model=weights/yolov8n.torchscript source=ultralytics/assets/bus.jpg device=0

yolo task=detect mode=predict imgsz=640 save=True save_txt=True save_conf=True save_crop=True conf=0.25 iou=0.6 data=ultralytics/cfg/datasets/coco128.yaml model=weights/yolov8n.torchscript source=../datasets/coco128/images/train2017 device=0
```

## onnx

> æ³¨æ„:
>
> `onnxruntime` å’Œ `onnxruntime-gpu` ä¸è¦åŒæ—¶å®‰è£…ï¼Œå¦åˆ™ä½¿ç”¨ `gpu` æ¨ç†æ—¶é€Ÿåº¦ä¼šå¾ˆæ…¢ï¼Œå¦‚æœåŒæ—¶å®‰è£…äº†2ä¸ªåŒ…ï¼Œè¦å…¨éƒ¨å¸è½½ï¼Œå†å®‰è£… `onnxruntime-gpu` æ‰èƒ½ä½¿ç”¨gpuæ¨ç†ï¼Œå¦åˆ™gpué€Ÿåº¦ä¼šå¾ˆæ…¢

```sh
yolo task=detect mode=predict imgsz=640 save=True save_txt=True save_conf=True save_crop=True conf=0.25 iou=0.6 data=ultralytics/cfg/datasets/coco128.yaml model=weights/yolov8n.onnx source=ultralytics/assets/bus.jpg device=0
yolo task=detect mode=predict imgsz=640 save=True save_txt=True save_conf=True save_crop=True conf=0.25 iou=0.6 data=ultralytics/cfg/datasets/coco128.yaml model=weights/yolov8n.onnx source=../datasets/coco128/images/train2017 device=0

yolo task=detect mode=predict imgsz=640 save=True save_txt=True save_conf=True save_crop=True conf=0.25 iou=0.6 data=ultralytics/cfg/datasets/coco128.yaml model=weights/yolov8n.fp16.onnx half=True source=ultralytics/assets/bus.jpg device=0           # fp16æ¨¡å‹éœ€è¦ half=True
yolo task=detect mode=predict imgsz=640 save=True save_txt=True save_conf=True save_crop=True conf=0.25 iou=0.6 data=ultralytics/cfg/datasets/coco128.yaml model=weights/yolov8n.fp16.onnx half=True source=../datasets/coco128/images/train2017 device=0

yolo task=detect mode=predict imgsz=640 save=True save_txt=True save_conf=True save_crop=True conf=0.25 iou=0.6 data=ultralytics/cfg/datasets/coco128.yaml model=weights/yolov8n.cpu.dynamic.onnx source=ultralytics/assets/bus.jpg device=0              # ä½¿ç”¨cpuå¯¼å‡ºçš„dynamicæ¨¡å‹å¯ä»¥ç”¨gpuæ¨ç†
yolo task=detect mode=predict imgsz=640 save=True save_txt=True save_conf=True save_crop=True conf=0.25 iou=0.6 data=ultralytics/cfg/datasets/coco128.yaml model=weights/yolov8n.cpu.dynamic.onnx source=../datasets/coco128/images/train2017 device=0
```

## openvino

> æ³¨æ„ï¼šopenvinoæ²¡æ³•ä½¿ç”¨cudaï¼Œä½†æ˜¯ä½¿ç”¨ `device=0` ä¼šæé«˜æ¨ç†é€Ÿåº¦

```sh
yolo task=detect mode=predict imgsz=640 save=True save_txt=True save_conf=True save_crop=True conf=0.25 iou=0.6 data=ultralytics/cfg/datasets/coco128.yaml model=weights/yolov8n_openvino_model source=ultralytics/assets/bus.jpg device=cpu

yolo task=detect mode=predict imgsz=640 save=True save_txt=True save_conf=True save_crop=True conf=0.25 iou=0.6 data=ultralytics/cfg/datasets/coco128.yaml model=weights/yolov8n_openvino_model source=../datasets/coco128/images/train2017 device=cpu
```

## tensorrt

```sh
yolo task=detect mode=predict imgsz=640 save=True save_txt=True save_conf=True save_crop=True conf=0.25 iou=0.6 data=ultralytics/cfg/datasets/coco128.yaml model=weights/yolov8n.engine half=True source=ultralytics/assets/bus.jpg device=0                          # fp32æ¨¡å‹ä¹Ÿèƒ½ç”¨ --half æ¨ç†
yolo task=detect mode=predict imgsz=640 save=True save_txt=True save_conf=True save_crop=True conf=0.25 iou=0.6 data=ultralytics/cfg/datasets/coco128.yaml model=weights/yolov8n.engine half=True source=../datasets/coco128/images/train2017 device=0

yolo task=detect mode=predict imgsz=640 save=True save_txt=True save_conf=True save_crop=True conf=0.25 iou=0.6 data=ultralytics/cfg/datasets/coco128.yaml model=weights/yolov8n.fp16.engine half=True source=ultralytics/assets/bus.jpg device=0
yolo task=detect mode=predict imgsz=640 save=True save_txt=True save_conf=True save_crop=True conf=0.25 iou=0.6 data=ultralytics/cfg/datasets/coco128.yaml model=weights/yolov8n.fp16.engine half=True source=../datasets/coco128/images/train2017 device=0

yolo task=detect mode=predict imgsz=640 save=True save_txt=True save_conf=True save_crop=True conf=0.25 iou=0.6 data=ultralytics/cfg/datasets/coco128.yaml model=weights/yolov8n.fp32.dynamic.engine half=True source=ultralytics/assets/bus.jpg device=0             # fp32æ¨¡å‹ä¹Ÿèƒ½ç”¨ --half æ¨ç†
yolo task=detect mode=predict imgsz=640 save=True save_txt=True save_conf=True save_crop=True conf=0.25 iou=0.6 data=ultralytics/cfg/datasets/coco128.yaml model=weights/yolov8n.fp32.dynamic.engine half=True source=../datasets/coco128/images/train2017 device=0
```



# [å¯¼å‡º](https://docs.ultralytics.com/zh/modes/export/)

## å¯¼å‡ºæ¨¡å¼çš„å…³é”®ç‰¹æ€§

ä»¥ä¸‹æ˜¯ä¸€äº›çªå‡ºçš„åŠŸèƒ½ï¼š

- **ä¸€é”®å¯¼å‡ºï¼š** ç”¨äºå¯¼å‡ºåˆ°ä¸åŒæ ¼å¼çš„ç®€å•å‘½ä»¤ã€‚
- **æ‰¹é‡å¯¼å‡ºï¼š** æ”¯æŒæ‰¹æ¨ç†èƒ½åŠ›çš„æ¨¡å‹å¯¼å‡ºã€‚
- **ä¼˜åŒ–æ¨ç†ï¼š** å¯¼å‡ºçš„æ¨¡å‹é’ˆå¯¹æ›´å¿«çš„æ¨ç†æ—¶é—´è¿›è¡Œä¼˜åŒ–ã€‚
- **æ•™å­¦è§†é¢‘ï¼š** æä¾›æ·±å…¥æŒ‡å¯¼å’Œæ•™å­¦ï¼Œç¡®ä¿æµç•…çš„å¯¼å‡ºä½“éªŒã€‚

## ä½¿ç”¨ç¤ºä¾‹

å°† YOLOv8n æ¨¡å‹å¯¼å‡ºä¸º ONNX æˆ– TensorRT ç­‰ä¸åŒæ ¼å¼ã€‚æŸ¥çœ‹ä¸‹é¢çš„å‚æ•°éƒ¨åˆ†ï¼Œäº†è§£å®Œæ•´çš„å¯¼å‡ºå‚æ•°åˆ—è¡¨ã€‚

> python

```python
from ultralytics import YOLO

# åŠ è½½æ¨¡å‹
model = YOLO('yolov8n.pt')  # åŠ è½½å®˜æ–¹æ¨¡å‹
model = YOLO('path/to/best.pt')  # åŠ è½½è‡ªå®šä¹‰è®­ç»ƒçš„æ¨¡å‹

# å¯¼å‡ºæ¨¡å‹
model.export(format='onnx')
```

> cli

```sh
yolo export model=yolov8n.pt format=onnx  # å¯¼å‡ºå®˜æ–¹æ¨¡å‹
yolo export model=path/to/best.pt format=onnx  # å¯¼å‡ºè‡ªå®šä¹‰è®­ç»ƒçš„æ¨¡å‹
```

## å‚æ•°

YOLO æ¨¡å‹çš„å¯¼å‡ºè®¾ç½®æ˜¯æŒ‡ç”¨äºåœ¨å…¶ä»–ç¯å¢ƒæˆ–å¹³å°ä¸­ä½¿ç”¨æ¨¡å‹æ—¶ä¿å­˜æˆ–å¯¼å‡ºæ¨¡å‹çš„å„ç§é…ç½®å’Œé€‰é¡¹ã€‚è¿™äº›è®¾ç½®ä¼šå½±å“æ¨¡å‹çš„æ€§èƒ½ã€å¤§å°å’Œä¸ä¸åŒç³»ç»Ÿçš„å…¼å®¹æ€§ã€‚ä¸€äº›å¸¸è§çš„ YOLO å¯¼å‡ºè®¾ç½®åŒ…æ‹¬å¯¼å‡ºçš„æ¨¡å‹æ–‡ä»¶æ ¼å¼ï¼ˆä¾‹å¦‚ ONNXã€TensorFlow SavedModelï¼‰ã€æ¨¡å‹å°†åœ¨å“ªä¸ªè®¾å¤‡ä¸Šè¿è¡Œï¼ˆä¾‹å¦‚ CPUã€GPUï¼‰ä»¥åŠæ˜¯å¦åŒ…å«é™„åŠ åŠŸèƒ½ï¼Œå¦‚é®ç½©æˆ–æ¯ä¸ªæ¡†å¤šä¸ªæ ‡ç­¾ã€‚å…¶ä»–å¯èƒ½å½±å“å¯¼å‡ºè¿‡ç¨‹çš„å› ç´ åŒ…æ‹¬æ¨¡å‹ç”¨é€”çš„å…·ä½“ç»†èŠ‚ä»¥åŠç›®æ ‡ç¯å¢ƒæˆ–å¹³å°çš„è¦æ±‚æˆ–é™åˆ¶ã€‚é‡è¦çš„æ˜¯è¦ä»”ç»†è€ƒè™‘å’Œé…ç½®è¿™äº›è®¾ç½®ï¼Œä»¥ç¡®ä¿å¯¼å‡ºçš„æ¨¡å‹é’ˆå¯¹é¢„æœŸç”¨ä¾‹ç»è¿‡ä¼˜åŒ–ï¼Œå¹¶ä¸”å¯ä»¥åœ¨ç›®æ ‡ç¯å¢ƒä¸­æœ‰æ•ˆä½¿ç”¨ã€‚

| é”®          | å€¼              | æè¿°                                                |
| :---------- | :-------------- | :-------------------------------------------------- |
| `format`    | `'torchscript'` | å¯¼å‡ºçš„æ ¼å¼                                          |
| `imgsz`     | `640`           | å›¾åƒå°ºå¯¸ï¼Œå¯ä»¥æ˜¯æ ‡é‡æˆ– (h, w) åˆ—è¡¨ï¼Œæ¯”å¦‚ (640, 480) |
| `keras`     | `False`         | ä½¿ç”¨ Keras å¯¼å‡º TF SavedModel                       |
| `optimize`  | `False`         | TorchScriptï¼šä¸ºç§»åŠ¨è®¾å¤‡ä¼˜åŒ–                         |
| `half`      | `False`         | FP16 é‡åŒ–                                           |
| `int8`      | `False`         | INT8 é‡åŒ–                                           |
| `dynamic`   | `False`         | ONNX/TensorRTï¼šåŠ¨æ€è½´                               |
| `simplify`  | `False`         | ONNX/TensorRTï¼šç®€åŒ–æ¨¡å‹                             |
| `opset`     | `None`          | ONNXï¼šopset ç‰ˆæœ¬ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸ºæœ€æ–°ç‰ˆæœ¬ï¼‰            |
| `workspace` | `4`             | TensorRTï¼šå·¥ä½œåŒºå¤§å°ï¼ˆGBï¼‰                          |
| `nms`       | `False`         | CoreMLï¼šæ·»åŠ  NMS                                    |

## å¯¼å‡ºæ ¼å¼

ä¸‹è¡¨ä¸­æä¾›äº†å¯ç”¨çš„ YOLOv8 å¯¼å‡ºæ ¼å¼ã€‚æ‚¨å¯ä»¥ä½¿ç”¨ `format` å‚æ•°å¯¼å‡ºä»»ä½•æ ¼å¼çš„æ¨¡å‹ï¼Œæ¯”å¦‚ `format='onnx'` æˆ– `format='engine'`ã€‚

| æ ¼å¼                                                         | `format` å‚æ•° | æ¨¡å‹                      | å…ƒæ•°æ® | å‚æ•°                                                |
| :----------------------------------------------------------- | :------------ | :------------------------ | :----- | :-------------------------------------------------- |
| [PyTorch](https://pytorch.org/)                              | -             | `yolov8n.pt`              | âœ…      | -                                                   |
| [TorchScript](https://pytorch.org/docs/stable/jit.html)      | `torchscript` | `yolov8n.torchscript`     | âœ…      | `imgsz`, `optimize`                                 |
| [ONNX](https://onnx.ai/)                                     | `onnx`        | `yolov8n.onnx`            | âœ…      | `imgsz`, `half`, `dynamic`, `simplify`, `opset`     |
| [OpenVINO](https://docs.openvino.ai/latest/index.html)       | `openvino`    | `yolov8n_openvino_model/` | âœ…      | `imgsz`, `half`, `int8`                             |
| [TensorRT](https://developer.nvidia.com/tensorrt)            | `engine`      | `yolov8n.engine`          | âœ…      | `imgsz`, `half`, `dynamic`, `simplify`, `workspace` |
| [CoreML](https://github.com/apple/coremltools)               | `coreml`      | `yolov8n.mlpackage`       | âœ…      | `imgsz`, `half`, `int8`, `nms`                      |
| [TF SavedModel](https://www.tensorflow.org/guide/saved_model) | `saved_model` | `yolov8n_saved_model/`    | âœ…      | `imgsz`, `keras`, `int8`                            |
| [TF GraphDef](https://www.tensorflow.org/api_docs/python/tf/Graph) | `pb`          | `yolov8n.pb`              | âŒ      | `imgsz`                                             |
| [TF Lite](https://www.tensorflow.org/lite)                   | `tflite`      | `yolov8n.tflite`          | âœ…      | `imgsz`, `half`, `int8`                             |
| [TF Edge TPU](https://coral.ai/docs/edgetpu/models-intro/)   | `edgetpu`     | `yolov8n_edgetpu.tflite`  | âœ…      | `imgsz`                                             |
| [TF.js](https://www.tensorflow.org/js)                       | `tfjs`        | `yolov8n_web_model/`      | âœ…      | `imgsz`, `half`, `int8`                             |
| [PaddlePaddle](https://github.com/PaddlePaddle)              | `paddle`      | `yolov8n_paddle_model/`   | âœ…      | `imgsz`                                             |
| [ncnn](https://github.com/Tencent/ncnn)                      | `ncnn`        | `yolov8n_ncnn_model/`     | âœ…      | `imgsz`, `half`                                     |

> example

```sh
yolo export model=yolov8n.pt format=onnx  # export official model
yolo export model=path/to/best.pt format=onnx  # export custom trained model
```

## torchscript

```sh
yolo task=detect mode=export imgsz=640 model=weights/yolov8n.pt format=torchscript device=0
yolo task=detect mode=export imgsz=640 model=weights/yolov8n.pt format=torchscript device=cpu optimize=True # optimize not compatible with cuda devices, i.e. use device=cpu
```

## onnx

> æ³¨æ„:
>
> `onnxruntime` å’Œ `onnxruntime-gpu` ä¸è¦åŒæ—¶å®‰è£…ï¼Œå¦åˆ™ä½¿ç”¨ `gpu` æ¨ç†æ—¶é€Ÿåº¦ä¼šå¾ˆæ…¢ï¼Œå¦‚æœåŒæ—¶å®‰è£…äº†2ä¸ªåŒ…ï¼Œè¦å…¨éƒ¨å¸è½½ï¼Œå†å®‰è£…`onnxruntime-gpu` æ‰èƒ½ä½¿ç”¨gpuæ¨ç†ï¼Œå¦åˆ™gpué€Ÿåº¦ä¼šå¾ˆæ…¢

```sh
yolo task=detect mode=export imgsz=640 model=weights/yolov8n.pt format=onnx simplify=True device=0

yolo task=detect mode=export imgsz=640 model=weights/yolov8n.pt format=onnx simplify=True device=0 half=True                # half=True only compatible with GPU export, i.e. use device=0

yolo task=detect mode=export imgsz=640 model=weights/yolov8n.pt format=onnx simplify=True device=cpu dynamic=True

yolo task=detect mode=export imgsz=640 model=weights/yolov8n.pt format=onnx simplify=True device=cpu half=True dynamic=True  # å¯¼å‡ºå¤±è´¥ half=True not compatible with dynamic=True, i.e. use only one.
```

### opencvä½¿ç”¨çš„onnx

> https://github.com/ultralytics/ultralytics/tree/main/examples/YOLOv8-OpenCV-ONNX-Python

```sh
yolo task=detect mode=export imgsz=640 model=weights/yolov8n.pt format=onnx simplify=True device=0 opset=12             # opsetå¿…é¡»ä¸º12

yolo task=detect mode=export imgsz=640 model=weights/yolov8n.pt format=onnx simplify=True device=0 half=True opset=12   # opsetå¿…é¡»ä¸º12

# opencvä¸æ”¯æŒdynamic
```

## openvino

```sh
yolo task=detect mode=export imgsz=640 model=weights/yolov8n.pt format=openvino device=cpu

yolo task=detect mode=export imgsz=640 model=weights/yolov8n.pt format=openvino device=cpu half=True

yolo task =detect mode=export imgsz=640 model=weights/yolov8n.pt format=openvino device=cpu int8=True data=ultralytics/cfg/datasets/coco128.yaml # INT8 export requires a data argument for calibration
```

### é€šè¿‡openvinoçš„`mo`å‘½ä»¤å°†onnxè½¬æ¢ä¸ºopenvinoæ ¼å¼(æ”¯æŒ**fp16**)

> https://docs.openvino.ai/latest/notebooks/102-pytorch-onnx-to-openvino-with-output.html

```sh
mo --input_model "onnx_path" --output_dir "output_path" --compress_to_fp16

mo --input_model "onnx_path" --output_dir "output_path" --compress_to_fp16
```

#### ä»£ç æ–¹å¼

```python
from openvino.tools import mo
from openvino.runtime import serialize

onnx_path = "onnx_path"

# fp32 IR model
fp32_path = "fp32_path"
output_path = fp32_path + ".xml"
print(f"Export ONNX to OpenVINO FP32 IR to: {output_path}")
model = mo.convert_model(onnx_path)
serialize(model, output_path)

# fp16 IR model
fp16_path = "fp16_path"
output_path = fp16_path + ".xml"

print(f"Export ONNX to OpenVINO FP16 IR to: {output_path}")
model = mo.convert_model(onnx_path, compress_to_fp16=True)
serialize(model, output_path)
```

### export failure  0.9s: DLL load failed while importing ie_api

> https://blog.csdn.net/qq_26815239/article/details/123047840
>
> å¦‚æœä½ ä½¿ç”¨çš„æ˜¯ Python 3.8 æˆ–æ›´é«˜ç‰ˆæœ¬ï¼Œå¹¶ä¸”æ˜¯åœ¨Windowsç³»ç»Ÿä¸‹é€šè¿‡pipå®‰è£…çš„openvinoï¼Œé‚£ä¹ˆè¯¥é”™è¯¯çš„è§£å†³æ–¹æ¡ˆå¦‚ä¸‹ï¼š

1. è¿›å…¥ç›®å½• `your\env\site-packages\openvino\inference_engine`
2. æ‰“å¼€æ–‡ä»¶ `__init__.py`
3. 26è¡Œä¸‹æ·»åŠ ä¸€è¡Œ

```python
        if os.path.isdir(lib_path):
            # On Windows, with Python >= 3.8, DLLs are no longer imported from the PATH.
            if (3, 8) <= sys.version_info:
                os.add_dll_directory(os.path.abspath(lib_path))
                os.environ['PATH'] = os.path.abspath(lib_path) + ';' + os.environ['PATH']	# æ·»åŠ è¿™ä¸€è¡Œ
```

## tensorrt

```sh
yolo task=detect mode=export imgsz=640 model=weights/yolov8n.pt format=engine simplify=True device=0 # å¯ä»¥ç”¨simplifyçš„onnx

yolo task=detect mode=export imgsz=640 model=weights/yolov8n.pt format=engine simplify=True device=0 half=True
```

## ncnn

```sh
yolo task=detect mode=export imgsz=640 model=weights/yolov8n.pt format=ncnn simplify=True device=0 # å¯ä»¥ç”¨simplifyçš„onnx

yolo task=detect mode=export imgsz=640 model=weights/yolov8n.pt format=ncnn simplify=True device=0 half=True
```

## onnx openvino tensorrt

> ç›®å‰ä¸æ”¯æŒåŒæ—¶å¯¼å‡ºå¤šç§æ ¼å¼ï¼Œæ¯ç§æ ¼å¼éƒ½è¦å•ç‹¬å¯¼å‡º

# [è·Ÿè¸ª](https://docs.ultralytics.com/zh/modes/track/)

## ä¸€ç¥ç‰¹ç‚¹

Ultralytics YOLOæ‰©å±•äº†å…¶ç‰©ä½“æ£€æµ‹åŠŸèƒ½ï¼Œä»¥æä¾›å¼ºå¤§ä¸”å¤šåŠŸèƒ½çš„ç‰©ä½“è¿½è¸ªï¼š

- **å®æ—¶è¿½è¸ªï¼š** åœ¨é«˜å¸§ç‡è§†é¢‘ä¸­æ— ç¼è¿½è¸ªç‰©ä½“ã€‚
- **æ”¯æŒå¤šä¸ªè¿½è¸ªå™¨ï¼š** ä»å¤šç§æˆç†Ÿçš„è¿½è¸ªç®—æ³•ä¸­é€‰æ‹©ã€‚
- **è‡ªå®šä¹‰è¿½è¸ªå™¨é…ç½®ï¼š** é€šè¿‡è°ƒæ•´å„ç§å‚æ•°æ¥å®šåˆ¶è¿½è¸ªç®—æ³•ï¼Œä»¥æ»¡è¶³ç‰¹å®šéœ€æ±‚ã€‚

## å¯ç”¨çš„è¿½è¸ªå™¨

Ultralytics YOLOæ”¯æŒä»¥ä¸‹è¿½è¸ªç®—æ³•ã€‚å¯ä»¥é€šè¿‡ä¼ é€’ç›¸å…³çš„YAMLé…ç½®æ–‡ä»¶å¦‚`tracker=tracker_type.yaml`æ¥å¯ç”¨ï¼š

- [BoT-SORT](https://github.com/NirAharon/BoT-SORT) - ä½¿ç”¨ `botsort.yaml` å¯ç”¨æ­¤è¿½è¸ªå™¨ã€‚
- [ByteTrack](https://github.com/ifzhang/ByteTrack) - ä½¿ç”¨ `bytetrack.yaml` å¯ç”¨æ­¤è¿½è¸ªå™¨ã€‚

é»˜è®¤è¿½è¸ªå™¨æ˜¯BoT-SORTã€‚



## è¿½è¸ª

è¦åœ¨è§†é¢‘æµä¸­è¿è¡Œè¿½è¸ªå™¨ï¼Œè¯·ä½¿ç”¨å·²è®­ç»ƒçš„æ£€æµ‹ã€åˆ†å‰²æˆ–å§¿æ€æ¨¡å‹ï¼Œä¾‹å¦‚YOLOv8nã€YOLOv8n-segå’ŒYOLOv8n-poseã€‚



> python

```python
from ultralytics import YOLO

# åŠ è½½å®˜æ–¹æˆ–è‡ªå®šä¹‰æ¨¡å‹
model = YOLO('yolov8n.pt')  # åŠ è½½ä¸€ä¸ªå®˜æ–¹çš„æ£€æµ‹æ¨¡å‹
model = YOLO('yolov8n-seg.pt')  # åŠ è½½ä¸€ä¸ªå®˜æ–¹çš„åˆ†å‰²æ¨¡å‹
model = YOLO('yolov8n-pose.pt')  # åŠ è½½ä¸€ä¸ªå®˜æ–¹çš„å§¿æ€æ¨¡å‹
model = YOLO('path/to/best.pt')  # åŠ è½½ä¸€ä¸ªè‡ªå®šä¹‰è®­ç»ƒçš„æ¨¡å‹

# ä½¿ç”¨æ¨¡å‹è¿›è¡Œè¿½è¸ª
results = model.track(source="https://youtu.be/LNwODJXcvt4", show=True)  # ä½¿ç”¨é»˜è®¤è¿½è¸ªå™¨è¿›è¡Œè¿½è¸ª
results = model.track(source="https://youtu.be/LNwODJXcvt4", show=True, tracker="bytetrack.yaml")  # ä½¿ç”¨ByteTrackè¿½è¸ªå™¨è¿›è¡Œè¿½è¸ª
```

> cli

```sh
# ä½¿ç”¨å‘½ä»¤è¡Œç•Œé¢è¿›è¡Œå„ç§æ¨¡å‹çš„è¿½è¸ª
yolo track model=yolov8n.pt source="https://youtu.be/LNwODJXcvt4"  # å®˜æ–¹æ£€æµ‹æ¨¡å‹
yolo track model=yolov8n-seg.pt source="https://youtu.be/LNwODJXcvt4"  # å®˜æ–¹åˆ†å‰²æ¨¡å‹
yolo track model=yolov8n-pose.pt source="https://youtu.be/LNwODJXcvt4"  # å®˜æ–¹å§¿æ€æ¨¡å‹
yolo track model=path/to/best.pt source="https://youtu.be/LNwODJXcvt4"  # è‡ªå®šä¹‰è®­ç»ƒæ¨¡å‹

# ä½¿ç”¨ByteTrackè¿½è¸ªå™¨è¿›è¡Œè¿½è¸ª
yolo track model=path/to/best.pt tracker="bytetrack.yaml"
```

## é…ç½®

### è¿½è¸ªå‚æ•°

è¿½è¸ªé…ç½®ä¸é¢„æµ‹æ¨¡å¼å…±äº«ä¸€äº›å±æ€§ï¼Œå¦‚`conf`ã€`iou`å’Œ`show`ã€‚æœ‰å…³è¿›ä¸€æ­¥é…ç½®ï¼Œè¯·å‚è§[é¢„æµ‹](https://docs.ultralytics.com/zh/modes/predict)æ¨¡å‹é¡µé¢ã€‚

> python

```sh
from ultralytics import YOLO

# é…ç½®è¿½è¸ªå‚æ•°å¹¶è¿è¡Œè¿½è¸ªå™¨
model = YOLO('yolov8n.pt')
results = model.track(source="https://youtu.be/LNwODJXcvt4", conf=0.3, iou=0.5, show=True)
```

> cli

```sh
# ä½¿ç”¨å‘½ä»¤è¡Œç•Œé¢é…ç½®è¿½è¸ªå‚æ•°å¹¶è¿è¡Œè¿½è¸ªå™¨
yolo track model=yolov8n.pt source="https://youtu.be/LNwODJXcvt4" conf=0.3, iou=0.5 show
```

### é€‰æ‹©è¿½è¸ªå™¨

Ultralyticsè¿˜å…è®¸æ‚¨ä½¿ç”¨ä¿®æ”¹åçš„è¿½è¸ªå™¨é…ç½®æ–‡ä»¶ã€‚è¦æ‰§è¡Œæ­¤æ“ä½œï¼Œåªéœ€ä»[ultralytics/cfg/trackers](https://github.com/ultralytics/ultralytics/tree/main/ultralytics/cfg/trackers)ä¸­å¤åˆ¶ä¸€ä¸ªè¿½è¸ªå™¨é…ç½®æ–‡ä»¶ï¼ˆä¾‹å¦‚ï¼Œ`custom_tracker.yaml`ï¼‰å¹¶æ ¹æ®æ‚¨çš„éœ€æ±‚ä¿®æ”¹ä»»ä½•é…ç½®ï¼ˆé™¤äº†`tracker_type`ï¼‰ã€‚



> python

```python
from ultralytics import YOLO

# åŠ è½½æ¨¡å‹å¹¶ä½¿ç”¨è‡ªå®šä¹‰é…ç½®æ–‡ä»¶è¿è¡Œè¿½è¸ªå™¨
model = YOLO('yolov8n.pt')
results = model.track(source="https://youtu.be/LNwODJXcvt4", tracker='custom_tracker.yaml')
```

> cli

```sh
# ä½¿ç”¨å‘½ä»¤è¡Œç•Œé¢åŠ è½½æ¨¡å‹å¹¶ä½¿ç”¨è‡ªå®šä¹‰é…ç½®æ–‡ä»¶è¿è¡Œè¿½è¸ªå™¨
yolo track model=yolov8n.pt source="https://youtu.be/LNwODJXcvt4" tracker='custom_tracker.yaml'
```

# [Tune](https://docs.ultralytics.com/integrations/ray-tune/)

## Usage

```python
from ultralytics import YOLO

# Load a YOLOv8n model
model = YOLO('yolov8n.pt')

# Start tuning hyperparameters for YOLOv8n training on the COCO8 dataset
result_grid = model.tune(data='coco8.yaml', use_ray=True, iterations=10)
```

## `tune()` Method Parameters

The `tune()` method in YOLOv8 provides an easy-to-use interface for hyperparameter tuning with Ray Tune. It accepts several arguments that allow you to customize the tuning process. Below is a detailed explanation of each parameter:

| Parameter       | Type             | Description                                                  | Default Value |
| :-------------- | :--------------- | :----------------------------------------------------------- | :------------ |
| `data`          | `str`            | The dataset configuration file (in YAML format) to run the tuner on. This file should specify the training and validation data paths, as well as other dataset-specific settings. |               |
| `space`         | `dict, optional` | A dictionary defining the hyperparameter search space for Ray Tune. Each key corresponds to a hyperparameter name, and the value specifies the range of values to explore during tuning. If not provided, YOLOv8 uses a default search space with various hyperparameters. |               |
| `grace_period`  | `int, optional`  | The grace period in epochs for the [ASHA scheduler](https://docs.ray.io/en/latest/tune/api/schedulers.html) in Ray Tune. The scheduler will not terminate any trial before this number of epochs, allowing the model to have some minimum training before making a decision on early stopping. | 10            |
| `gpu_per_trial` | `int, optional`  | The number of GPUs to allocate per trial during tuning. This helps manage GPU usage, particularly in multi-GPU environments. If not provided, the tuner will use all available GPUs. | None          |
| `iterations`    | `int, optional`  | The maximum number of trials to run during tuning. This parameter helps control the total number of hyperparameter combinations tested, ensuring the tuning process does not run indefinitely. | 10            |
| `**train_args`  | `dict, optional` | Additional arguments to pass to the `train()` method during tuning. These arguments can include settings like the number of training epochs, batch size, and other training-specific configurations. | {}            |

By customizing these parameters, you can fine-tune the hyperparameter optimization process to suit your specific needs and available computational resources.



## Default Search Space Description

The following table lists the default search space parameters for hyperparameter tuning in YOLOv8 with Ray Tune. Each parameter has a specific value range defined by `tune.uniform()`.

| Parameter         | Value Range                | Description                              |
| :---------------- | :------------------------- | :--------------------------------------- |
| `lr0`             | `tune.uniform(1e-5, 1e-1)` | Initial learning rate                    |
| `lrf`             | `tune.uniform(0.01, 1.0)`  | Final learning rate factor               |
| `momentum`        | `tune.uniform(0.6, 0.98)`  | Momentum                                 |
| `weight_decay`    | `tune.uniform(0.0, 0.001)` | Weight decay                             |
| `warmup_epochs`   | `tune.uniform(0.0, 5.0)`   | Warmup epochs                            |
| `warmup_momentum` | `tune.uniform(0.0, 0.95)`  | Warmup momentum                          |
| `box`             | `tune.uniform(0.02, 0.2)`  | Box loss weight                          |
| `cls`             | `tune.uniform(0.2, 4.0)`   | Class loss weight                        |
| `hsv_h`           | `tune.uniform(0.0, 0.1)`   | Hue augmentation range                   |
| `hsv_s`           | `tune.uniform(0.0, 0.9)`   | Saturation augmentation range            |
| `hsv_v`           | `tune.uniform(0.0, 0.9)`   | Value (brightness) augmentation range    |
| `degrees`         | `tune.uniform(0.0, 45.0)`  | Rotation augmentation range (degrees)    |
| `translate`       | `tune.uniform(0.0, 0.9)`   | Translation augmentation range           |
| `scale`           | `tune.uniform(0.0, 0.9)`   | Scaling augmentation range               |
| `shear`           | `tune.uniform(0.0, 10.0)`  | Shear augmentation range (degrees)       |
| `perspective`     | `tune.uniform(0.0, 0.001)` | Perspective augmentation range           |
| `flipud`          | `tune.uniform(0.0, 1.0)`   | Vertical flip augmentation probability   |
| `fliplr`          | `tune.uniform(0.0, 1.0)`   | Horizontal flip augmentation probability |
| `mosaic`          | `tune.uniform(0.0, 1.0)`   | Mosaic augmentation probability          |
| `mixup`           | `tune.uniform(0.0, 1.0)`   | Mixup augmentation probability           |
| `copy_paste`      | `tune.uniform(0.0, 1.0)`   | Copy-paste augmentation probability      |

## Custom Search Space Example

In this example, we demonstrate how to use a custom search space for hyperparameter tuning with Ray Tune and YOLOv8. By providing a custom search space, you can focus the tuning process on specific hyperparameters of interest.

```python
from ultralytics import YOLO

# Define a YOLO model
model = YOLO("yolov8n.pt")

# Run Ray Tune on the model
result_grid = model.tune(data="coco128.yaml",
                         space={"lr0": tune.uniform(1e-5, 1e-1)},
                         epochs=50,
                         use_ray=True)
```

In the code snippet above, we create a YOLO model with the "yolov8n.pt" pretrained weights. Then, we call the `tune()` method, specifying the dataset configuration with "coco128.yaml". We provide a custom search space for the initial learning rate `lr0` using a dictionary with the key "lr0" and the value `tune.uniform(1e-5, 1e-1)`. Finally, we pass additional training arguments, such as the number of epochs directly to the tune method as `epochs=50`.

## Processing Ray Tune Results

After running a hyperparameter tuning experiment with Ray Tune, you might want to perform various analyses on the obtained results. This guide will take you through common workflows for processing and analyzing these results.

### Loading Tune Experiment Results from a Directory

After running the tuning experiment with `tuner.fit()`, you can load the results from a directory. This is useful, especially if you're performing the analysis after the initial training script has exited.

```python
experiment_path = f"{storage_path}/{exp_name}"
print(f"Loading results from {experiment_path}...")

restored_tuner = tune.Tuner.restore(experiment_path, trainable=train_mnist)
result_grid = restored_tuner.get_results()
```

### Basic Experiment-Level Analysis

Get an overview of how trials performed. You can quickly check if there were any errors during the trials.

```python
if result_grid.errors:
    print("One or more trials failed!")
else:
    print("No errors!")
```

### Basic Trial-Level Analysis

Access individual trial hyperparameter configurations and the last reported metrics.

```python
for i, result in enumerate(result_grid):
    print(f"Trial #{i}: Configuration: {result.config}, Last Reported Metrics: {result.metrics}")
```

### Plotting the Entire History of Reported Metrics for a Trial

You can plot the history of reported metrics for each trial to see how the metrics evolved over time.



```python
import matplotlib.pyplot as plt

for result in result_grid:
    plt.plot(result.metrics_dataframe["training_iteration"], result.metrics_dataframe["mean_accuracy"], label=f"Trial {i}")

plt.xlabel('Training Iterations')
plt.ylabel('Mean Accuracy')
plt.legend()
plt.show()
```

# yolo special commands

## yolo help

```sh
> yolo help

    Arguments received: ['yolo', 'help']. Ultralytics 'yolo' commands use the following syntax:

        yolo TASK MODE ARGS

        Where   TASK (optional) is one of ('detect', 'segment', 'classify', 'pose')
                MODE (required) is one of ('train', 'val', 'predict', 'export', 'track', 'benchmark')
                ARGS (optional) are any number of custom 'arg=value' pairs like 'imgsz=320' that override defaults.
                    See all ARGS at https://docs.ultralytics.com/usage/cfg or with 'yolo cfg'

    1. Train a detection model for 10 epochs with an initial learning_rate of 0.01
        yolo train data=coco128.yaml model=yolov8n.pt epochs=10 lr0=0.01

    2. Predict a YouTube video using a pretrained segmentation model at image size 320:
        yolo predict model=yolov8n-seg.pt source='https://youtu.be/LNwODJXcvt4' imgsz=320

    3. Val a pretrained detection model at batch-size 1 and image size 640:
        yolo val model=yolov8n.pt data=coco128.yaml batch=1 imgsz=640

    4. Export a YOLOv8n classification model to ONNX format at image size 224 by 128 (no TASK required)
        yolo export model=yolov8n-cls.pt format=onnx imgsz=224,128

    5. Run special commands:
        yolo help
        yolo checks
        yolo version
        yolo settings
        yolo copy-cfg
        yolo cfg

    Docs: https://docs.ultralytics.com
    Community: https://community.ultralytics.com
    GitHub: https://github.com/ultralytics/ultralytics
```

## yolo checks

```sh
> yolo checks
Ultralytics YOLOv8.0.195  Python-3.11.4 torch-2.1.0+cu121 CUDA:0 (NVIDIA GeForce GTX 1080 Ti, 11264MiB)
Setup complete  (16 CPUs, 31.9 GB RAM, 152.1/200.0 GB disk)

OS                  Windows-10-10.0.19044-SP0
Environment         Windows
Python              3.11.4
Install             git
RAM                 31.91 GB
CPU                 Intel Core(TM) i7-10700 2.90GHz
CUDA                12.1

matplotlib           3.8.0>=3.3.0
numpy                1.26.0>=1.22.2
opencv-python        4.8.1.78>=4.6.0
pillow               10.0.1>=7.1.2
pyyaml               6.0.1>=5.3.1
requests             2.31.0>=2.23.0
scipy                1.10.1>=1.4.1
torch                2.1.0+cu121>=1.8.0
torchvision          0.16.0+cu121>=0.9.0
tqdm                 4.66.1>=4.64.0
pandas               2.1.1>=1.1.4
seaborn              0.13.0>=0.11.0
psutil               5.9.5
py-cpuinfo           9.0.0
thop                 0.1.1-2209072238>=0.1.1
```

## yolo version

```sh
> yolo version
8.0.195
```

## yolo settings

```sh
> yolo settings
 Learn about settings at https://docs.ultralytics.com/quickstart/#ultralytics-settings
Printing 'C:\Users\Administrator\AppData\Roaming\Ultralytics\settings.yaml'

settings_version: 0.0.4
datasets_dir: D:\ml\code\datasets
weights_dir: d:\ml\code\yolov8-ultralytics\weights
runs_dir: d:\ml\code\yolov8-ultralytics\runs
uuid: 062fa24c9a04873db7e870e2df7f4297a2745f5a740d9e7bd868b5884cf0b91a
sync: true
api_key: ''
clearml: true
comet: true
dvc: true
hub: true
mlflow: true
neptune: true
raytune: true
tensorboard: true
wandb: true
```

## yolo copy-cfg

```sh
> yolo copy-cfg
D:\ml\code\yolov8-ultralytics\ultralytics\cfg\default.yaml copied to D:\ml\code\yolov8-ultralytics\default_copy.yaml
Example YOLO command with this new custom cfg:
    yolo cfg='D:\ml\code\yolov8-ultralytics\default_copy.yaml' imgsz=320 batch=8
```

## yolo cfg

```sh
> yolo cfg
Printing 'D:\ml\code\yolov8-ultralytics\ultralytics\cfg\default.yaml'

task: detect
mode: train
model: null
data: null
epochs: 100
patience: 50
batch: 16
imgsz: 640
save: true
save_period: -1
cache: false
device: null
workers: 8
project: null
name: null
exist_ok: false
pretrained: true
optimizer: auto
verbose: true
seed: 0
deterministic: true
single_cls: false
rect: false
cos_lr: false
close_mosaic: 10
resume: false
amp: true
fraction: 1.0
profile: false
freeze: None
overlap_mask: true
mask_ratio: 4
dropout: 0.0
val: true
split: val
save_json: false
save_hybrid: false
conf: null
iou: 0.7
max_det: 300
half: false
dnn: false
plots: true
source: null
show: false
save_txt: false
save_conf: false
save_crop: false
show_labels: true
show_conf: true
vid_stride: 1
stream_buffer: false
line_width: null
visualize: false
augment: false
agnostic_nms: false
classes: null
retina_masks: false
boxes: true
format: torchscript
keras: false
optimize: false
int8: false
dynamic: false
simplify: false
opset: null
workspace: 4
nms: false
lr0: 0.01
lrf: 0.01
momentum: 0.937
weight_decay: 0.0005
warmup_epochs: 3.0
warmup_momentum: 0.8
warmup_bias_lr: 0.1
box: 7.5
cls: 0.5
dfl: 1.5
pose: 12.0
kobj: 1.0
label_smoothing: 0.0
nbs: 64
hsv_h: 0.015
hsv_s: 0.7
hsv_v: 0.4
degrees: 0.0
translate: 0.1
scale: 0.5
shear: 0.0
perspective: 0.0
flipud: 0.0
fliplr: 0.5
mosaic: 1.0
mixup: 0.0
copy_paste: 0.0
cfg: null
tracker: botsort.yaml
```

