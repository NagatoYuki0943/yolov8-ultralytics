

# æœ¬åœ°å®‰è£…

```sh
git clone https://github.com/ultralytics/ultralytics
cd ultralytics
pip install -v -e .
# "-v" æŒ‡è¯¦ç»†è¯´æ˜ï¼Œæˆ–æ›´å¤šçš„è¾“å‡º
# "-e" è¡¨ç¤ºåœ¨å¯ç¼–è¾‘æ¨¡å¼ä¸‹å®‰è£…é¡¹ç›®ï¼Œå› æ­¤å¯¹ä»£ç æ‰€åšçš„ä»»ä½•æœ¬åœ°ä¿®æ”¹éƒ½ä¼šç”Ÿæ•ˆï¼Œä»è€Œæ— éœ€é‡æ–°å®‰è£…ã€‚
```

# [CLI](https://docs.ultralytics.com/usage/cli/)

The YOLO Command Line Interface (CLI) is the easiest way to get started training, validating, predicting and exporting YOLOv8 models.

The `yolo` command is used for all actions:

```sh
yolo TASK MODE ARGS
```

Where:

- `TASK` (optional) is one of `[detect, segment, classify]`. If it is not passed explicitly YOLOv8 will try to guess the `TASK` from the model type.
- `MODE` (required) is one of `[train, val, predict, export]`
- `ARGS` (optional) are any number of custom `arg=value` pairs like `imgsz=320` that override defaults. For a full list of available `ARGS` see the [Configuration](https://docs.ultralytics.com/usage/cfg/) page and `defaults.yaml` GitHub [source](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/yolo/cfg/default.yaml).

**Note:** Arguments MUST be passed as `arg=val` with an equals sign and a space between `arg=val` pairs

- `yolo predict model=yolov8n.pt imgsz=640 conf=0.25`  âœ…
- `yolo predict model yolov8n.pt imgsz 640 conf 0.25`  âŒ
- `yolo predict --model yolov8n.pt --imgsz 640 --conf 0.25`  âŒ

## Overriding default arguments

Default arguments can be overridden by simply passing them as arguments in the CLI in `arg=value` pairs.

```sh
yolo detect train data=coco128.yaml model=yolov8n.pt epochs=10 lr0=0.01

yolo segment predict model=yolov8n-seg.pt source='https://youtu.be/Zgi9g1ksQHc' imgsz=320

yolo segment predict model=yolov8n-seg.pt source='https://youtu.be/Zgi9g1ksQHc' imgsz=320
```

## Overriding default config file

You can override the `default.yaml` config file entirely by passing a new file with the `cfg` arguments, i.e. `cfg=custom.yaml`.

To do this first create a copy of `default.yaml` in your current working dir with the `yolo copy-cfg` command.

This will create `default_copy.yaml`, which you can then pass as `cfg=default_copy.yaml` along with any additional args, like `imgsz=320` in this example:

```sh
yolo copy-cfg
yolo cfg=default_copy.yaml imgsz=320
```

é»˜è®¤é…ç½®æ–‡ä»¶ä½ç½®åœ¨ `ultralytics/yolo/cfg/default.yaml`

```yaml
# Ultralytics YOLO ğŸš€, GPL-3.0 license
# Default training settings and hyperparameters for medium-augmentation COCO training

task: detect  # YOLO task, i.e. detect, segment, classify, pose
mode: train  # YOLO mode, i.e. train, val, predict, export, track, benchmark

# Train settings -------------------------------------------------------------------------------------------------------
model:  # path to model file, i.e. yolov8n.pt, yolov8n.yaml
data:  # path to data file, i.e. coco128.yaml
epochs: 100  # number of epochs to train for
patience: 50  # epochs to wait for no observable improvement for early stopping of training
batch: 16  # number of images per batch (-1 for AutoBatch)
imgsz: 640  # size of input images as integer or w,h
save: True  # save train checkpoints and predict results
save_period: -1 # Save checkpoint every x epochs (disabled if < 1)
cache: False  # True/ram, disk or False. Use cache for data loading
device:  # device to run on, i.e. cuda device=0 or device=0,1,2,3 or device=cpu
workers: 8  # number of worker threads for data loading (per RANK if DDP)
project:  # project name
name:  # experiment name, results saved to 'project/name' directory
exist_ok: False  # whether to overwrite existing experiment
pretrained: False  # whether to use a pretrained model
optimizer: SGD  # optimizer to use, choices=['SGD', 'Adam', 'AdamW', 'RMSProp']
verbose: True  # whether to print verbose output
seed: 0  # random seed for reproducibility
deterministic: True  # whether to enable deterministic mode
single_cls: False  # train multi-class data as single-class
image_weights: False  # use weighted image selection for training
rect: False  # support rectangular training if mode='train', support rectangular evaluation if mode='val'
cos_lr: False  # use cosine learning rate scheduler
close_mosaic: 10  # disable mosaic augmentation for final 10 epochs
resume: False  # resume training from last checkpoint
amp: True  # Automatic Mixed Precision (AMP) training, choices=[True, False], True runs AMP check
# Segmentation
overlap_mask: True  # masks should overlap during training (segment train only)
mask_ratio: 4  # mask downsample ratio (segment train only)
# Classification
dropout: 0.0  # use dropout regularization (classify train only)

# Val/Test settings ----------------------------------------------------------------------------------------------------
val: True  # validate/test during training
split: val  # dataset split to use for validation, i.e. 'val', 'test' or 'train'
save_json: False  # save results to JSON file
save_hybrid: False  # save hybrid version of labels (labels + additional predictions)
conf:  # object confidence threshold for detection (default 0.25 predict, 0.001 val)
iou: 0.7  # intersection over union (IoU) threshold for NMS
max_det: 300  # maximum number of detections per image
half: False  # use half precision (FP16)
dnn: False  # use OpenCV DNN for ONNX inference
plots: True  # save plots during train/val

# Prediction settings --------------------------------------------------------------------------------------------------
source:  # source directory for images or videos
show: False  # show results if possible
save_txt: False  # save results as .txt file
save_conf: False  # save results with confidence scores
save_crop: False  # save cropped images with results
hide_labels: False  # hide labels
hide_conf: False  # hide confidence scores
vid_stride: 1  # video frame-rate stride
line_thickness: 3  # bounding box thickness (pixels)
visualize: False  # visualize model features
augment: False  # apply image augmentation to prediction sources
agnostic_nms: False  # class-agnostic NMS
classes:  # filter results by class, i.e. class=0, or class=[0,2,3]
retina_masks: False  # use high-resolution segmentation masks
boxes: True  # Show boxes in segmentation predictions

# Export settings ------------------------------------------------------------------------------------------------------
format: torchscript  # format to export to
keras: False  # use Keras
optimize: False  # TorchScript: optimize for mobile
int8: False  # CoreML/TF INT8 quantization
dynamic: False  # ONNX/TF/TensorRT: dynamic axes
simplify: False  # ONNX: simplify model
opset:  # ONNX: opset version (optional)
workspace: 4  # TensorRT: workspace size (GB)
nms: False  # CoreML: add NMS

# Hyperparameters ------------------------------------------------------------------------------------------------------
lr0: 0.01  # initial learning rate (i.e. SGD=1E-2, Adam=1E-3)
lrf: 0.01  # final learning rate (lr0 * lrf)
momentum: 0.937  # SGD momentum/Adam beta1
weight_decay: 0.0005  # optimizer weight decay 5e-4
warmup_epochs: 3.0  # warmup epochs (fractions ok)
warmup_momentum: 0.8  # warmup initial momentum
warmup_bias_lr: 0.1  # warmup initial bias lr
box: 7.5  # box loss gain
cls: 0.5  # cls loss gain (scale with pixels)
dfl: 1.5  # dfl loss gain
fl_gamma: 0.0  # focal loss gamma (efficientDet default gamma=1.5)
label_smoothing: 0.0  # label smoothing (fraction)
nbs: 64  # nominal batch size
hsv_h: 0.015  # image HSV-Hue augmentation (fraction)
hsv_s: 0.7  # image HSV-Saturation augmentation (fraction)
hsv_v: 0.4  # image HSV-Value augmentation (fraction)
degrees: 0.0  # image rotation (+/- deg)
translate: 0.1  # image translation (+/- fraction)
scale: 0.5  # image scale (+/- gain)
shear: 0.0  # image shear (+/- deg)
perspective: 0.0  # image perspective (+/- fraction), range 0-0.001
flipud: 0.0  # image flip up-down (probability)
fliplr: 0.5  # image flip left-right (probability)
mosaic: 1.0  # image mosaic (probability)
mixup: 0.0  # image mixup (probability)
copy_paste: 0.0  # segment copy-paste (probability)

# Custom config.yaml ---------------------------------------------------------------------------------------------------
cfg:  # for overriding defaults.yaml

# Debug, do not modify -------------------------------------------------------------------------------------------------
v5loader: False  # use legacy YOLOv5 dataloader

# Tracker settings ------------------------------------------------------------------------------------------------------
tracker: botsort.yaml  # tracker type, ['botsort.yaml', 'bytetrack.yaml']
```





# [Configuration](https://docs.ultralytics.com/usage/cfg/)

YOLO settings and hyperparameters play a critical role in the model's performance, speed, and accuracy. These settings and hyperparameters can affect the model's behavior at various stages of the model development process, including training, validation, and prediction.

YOLOv8 'yolo' CLI commands use the following syntax:

```sh
yolo TASK MODE ARGS
yolo task=detect    mode=train    model=yolov8n.pt        args...
          classify       predict        yolov8n-cls.yaml  args...
          segment        val            yolov8n-seg.yaml  args...
                         export         yolov8n.pt        format=onnx  args...

# example    åé¢å¿…é¡»ä½¿ç”¨ = 
yolo predict model=yolov8n.pt source='https://ultralytics.com/images/bus.jpg'
yolo val detect data=coco.yaml device=0
yolo val detect data=coco128.yaml batch=1 device=0|cpu
```

Where:

- `TASK` (optional) is one of `[detect, segment, classify, pose]`. If it is not passed explicitly YOLOv8 will try to guess the `TASK` from the model type.
- `MODE` (required) is one of `[train, val, predict, export, track, benchmark]`
- `ARGS` (optional) are any number of custom `arg=value` pairs like `imgsz=320` that override defaults. For a full list of available `ARGS` see the [Configuration](https://docs.ultralytics.com/usage/cfg/) page and `defaults.yaml` GitHub [source](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/yolo/cfg/default.yaml).

## Tasks

YOLO models can be used for a variety of tasks, including detection, segmentation, classification and pose. These tasks differ in the type of output they produce and the specific problem they are designed to solve.

- **Detect**: For identifying and localizing objects or regions of interest in an image or video.
- **Segment**: For dividing an image or video into regions or pixels that correspond to different objects or classes.
- **Classify**: For predicting the class label of an input image.
- **Pose**: For identifying objects and estimating their keypoints in an image or video.

| Key    | Value      | Description                                     |
| :----- | :--------- | :---------------------------------------------- |
| `task` | `'detect'` | YOLO task, i.e. detect, segment, classify, pose |

## Modes

YOLO models can be used in different modes depending on the specific problem you are trying to solve. These modes include:

- **Train**: For training a YOLOv8 model on a custom dataset.

- **Val**: For validating a YOLOv8 model after it has been trained.

- **Predict**: For making predictions using a trained YOLOv8 model on new images or videos.

- **Export**: For exporting a YOLOv8 model to a format that can be used for deployment.

- **Track**: For tracking objects in real-time using a YOLOv8 model.

- **Benchmark**: For benchmarking YOLOv8 exports (ONNX, TensorRT, etc.) speed and accuracy.

| Key    | Value     | Description                                                  |
| :----- | :-------- | :----------------------------------------------------------- |
| `mode` | `'train'` | YOLO mode, i.e. train, val, predict, export, track, benchmark |

# æ•°æ®é›†

> å…ˆè¦æŠŠæ•°æ®é›†æ”¾å…¥datasetä¸­ï¼Œä¿®æ”¹data/ç›®å½•ä¸‹çš„yamlï¼Œè°ƒæ•´ä¸ºè‡ªå·±çš„æ•°æ®é›†ï¼Œéœ€è¦è°ƒæ•´è·¯å¾„ï¼Œåˆ†ç±»æ•°ï¼Œæ ‡ç­¾å

> yoloæ•°æ®é›†æ ¼å¼(yolov5çš„coco128å’Œéœ¹é›³å§å•¦Wzçš„yolo3ä¸ºä¾‹)
>
> txtå†…å®¹ï¼Œæ¯ä¸€è¡Œéƒ½æ˜¯ `3 0.933536 0.486124 0.030408 0.154487`
>
> æ˜¯ label ä¸­å¿ƒæ¨ªåæ ‡ä¸å›¾åƒå®½åº¦æ¯”å€¼ ä¸­å¿ƒçºµåæ ‡ä¸å›¾åƒé«˜åº¦æ¯”å€¼ bboxå®½åº¦ä¸å›¾åƒå®½åº¦æ¯”å€¼ bboxé«˜åº¦ä¸å›¾åƒå®½é«˜æ¯”å€¼

```
#-------------------------------------------#
# 	yolov5çš„coco128æ ¼å¼
# 	éœ€è¦åœ¨~data/coco128.yamlä¸­ä¿®æ”¹å¦‚ä¸‹ä¿¡æ¯
# 	nc: 10  # åˆ†ç±»æ•°è¦å’Œdatasetä¸­ä¸€è‡´
# 	names: ["aeroplane", "bicycle", "bird", "boat", "bottle": 5] # åˆ†ç±»åç§°
#-------------------------------------------#
datasets
â”œâ”€â”€ coco128
	â”œâ”€â”€ images
    â”‚	â”œâ”€â”€ train2017	è®­ç»ƒå›¾ç‰‡
    â”‚	â””â”€â”€ val2017		éªŒè¯å›¾ç‰‡
	â””â”€â”€ labels
    	â”œâ”€â”€ train2017	è®­ç»ƒæ ‡ç­¾txt
    	â””â”€â”€ val2017		éªŒè¯æ ‡ç­¾txt


#-------------------------------------------#
#	éœ¹é›³å§å•¦Wzçš„yolo3
#-------------------------------------------#
data
â”œâ”€â”€ pascal_voc_classes.json		å­˜æ”¾ç±»åˆ«ä¿¡æ¯ {"aeroplane": 1, "bicycle": 2, "bird": 3, "boat": 4, "bottle": 5}
â”œâ”€â”€ train
â”‚	â”œâ”€â”€ images		è®­ç»ƒå›¾ç‰‡
â”‚	â””â”€â”€ labels		è®­ç»ƒæ ‡ç­¾txt
â””â”€â”€ val
	â”œâ”€â”€ images		éªŒè¯å›¾ç‰‡
	â””â”€â”€ labels		éªŒè¯å›¾ç‰‡txt
```

> data/class20.yaml

```yaml
# YOLOv5 ğŸš€ by Ultralytics, GPL-3.0 license
# COCO128 dataset https://www.kaggle.com/ultralytics/coco128 (first 128 images from COCO train2017) by Ultralytics
# Example usage: python train.py --data coco128.yaml
# parent
# â”œâ”€â”€ yolov5
# â””â”€â”€ datasets
#     â””â”€â”€ yourname
#         â””â”€â”€ images/
#             â””â”€â”€ train2017/  å­˜æ”¾è®­ç»ƒå›¾ç‰‡
#             â””â”€â”€ val2017/    å­˜æ”¾éªŒè¯å›¾ç‰‡
#         â””â”€â”€ labels/
#             â””â”€â”€ train2017/  å­˜æ”¾è®­ç»ƒæ ‡ç­¾  class x_center y_center width height
#             â””â”€â”€ val2017/    å­˜æ”¾éªŒè¯æ ‡ç­¾


# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]
path: ./datasets/coco128  # dataset root dir
train: images/train2017  # train images (relative to 'path') 128 images
val: images/val2017  # val images (relative to 'path') 128 images
test:  # test images (optional)

# Classes
names:
  0: aeroplane
  1: bicycle
  2: bird
  3: boat
  4: bottle
  5: bus
  6: car
  7: cat
  8: chair
  9: cow
  10: diningtable
  11: dog
  12: horse
  13: motorbike
  14: person
  15: pottedplant
  16: sheep
  17: sofa
  18: train
  19: tvmonitor
```

# æ¨¡å‹

> ç„¶ååœ¨`models/yolov5*.yaml`ä¸­è®¾ç½®åˆ†ç±»æ•°

```yaml
# Parameters
nc: 20  # è°ƒæ•´ä¸ºè‡ªå·±çš„åˆ†ç±»æ•°
```

# ä¸‹è½½æƒé‡

> å°†ä¸‹è½½å¥½çš„æƒé‡æ”¾åˆ°`weights/`æ–‡ä»¶ä¸‹ä¸‹

## æ¨¡å‹

æ‰€æœ‰ YOLOv8 çš„é¢„è®­ç»ƒæ¨¡å‹éƒ½å¯ä»¥åœ¨è¿™é‡Œæ‰¾åˆ°ã€‚ç›®æ ‡æ£€æµ‹å’Œåˆ†å‰²æ¨¡å‹æ˜¯åœ¨ COCO æ•°æ®é›†ä¸Šé¢„è®­ç»ƒçš„ï¼Œè€Œåˆ†ç±»æ¨¡å‹æ˜¯åœ¨ ImageNet æ•°æ®é›†ä¸Šé¢„è®­ç»ƒçš„ã€‚

ç¬¬ä¸€æ¬¡ä½¿ç”¨æ—¶ï¼Œ[æ¨¡å‹](https://github.com/ultralytics/ultralytics/tree/main/ultralytics/models) ä¼šä» Ultralytics [å‘å¸ƒé¡µ](https://github.com/ultralytics/ultralytics/releases) è‡ªåŠ¨ä¸‹è½½ã€‚

| æ¨¡å‹                                                         | å°ºå¯¸ ï¼ˆåƒç´ ï¼‰ | mAPval 50-95 | æ¨ç†é€Ÿåº¦ CPU ONNX (ms) | æ¨ç†é€Ÿåº¦ A100 TensorRT (ms) | å‚æ•°é‡ (M) | FLOPs (B) |
| ------------------------------------------------------------ | ------------- | ------------ | ---------------------- | --------------------------- | ---------- | --------- |
| [YOLOv8n](https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt) | 640           | 37.3         | 80.4                   | 0.99                        | 3.2        | 8.7       |
| [YOLOv8s](https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8s.pt) | 640           | 44.9         | 128.4                  | 1.20                        | 11.2       | 28.6      |
| [YOLOv8m](https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m.pt) | 640           | 50.2         | 234.7                  | 1.83                        | 25.9       | 78.9      |
| [YOLOv8l](https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8l.pt) | 640           | 52.9         | 375.2                  | 2.39                        | 43.7       | 165.2     |
| [YOLOv8x](https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8x.pt) | 640           | 53.9         | 479.1                  | 3.53                        | 68.2       | 257.8     |

- **mAPval** ç»“æœéƒ½åœ¨ [COCO val2017](http://cocodataset.org/) æ•°æ®é›†ä¸Šï¼Œä½¿ç”¨å•æ¨¡å‹å•å°ºåº¦æµ‹è¯•å¾—åˆ°ã€‚
  å¤ç°å‘½ä»¤ `yolo val detect data=coco.yaml device=0`
- **æ¨ç†é€Ÿåº¦**ä½¿ç”¨ COCO éªŒè¯é›†å›¾ç‰‡æ¨ç†æ—¶é—´è¿›è¡Œå¹³å‡å¾—åˆ°ï¼Œæµ‹è¯•ç¯å¢ƒä½¿ç”¨ [Amazon EC2 P4d](https://aws.amazon.com/ec2/instance-types/p4/) å®ä¾‹ã€‚
  å¤ç°å‘½ä»¤ `yolo val detect data=coco128.yaml batch=1 device=0|cpu`

# æ˜¾å¡è®­ç»ƒ

Training settings for YOLO models refer to the various hyperparameters and configurations used to train the model on a dataset. These settings can affect the model's performance, speed, and accuracy. Some common YOLO training settings include the batch size, learning rate, momentum, and weight decay. Other factors that may affect the training process include the choice of optimizer, the choice of loss function, and the size and composition of the training dataset. It is important to carefully tune and experiment with these settings to achieve the best possible performance for a given task.

| Key               | Value    | Description                                                  |
| :---------------- | :------- | :----------------------------------------------------------- |
| `model`           | `None`   | path to model file, i.e. yolov8n.pt, yolov8n.yaml            |
| `data`            | `None`   | path to data file, i.e. coco128.yaml                         |
| `epochs`          | `100`    | number of epochs to train for                                |
| `patience`        | `50`     | epochs to wait for no observable improvement for early stopping of training |
| `batch`           | `16`     | number of images per batch (-1 for AutoBatch)                |
| `imgsz`           | `640`    | size of input images as integer or w,h                       |
| `save`            | `True`   | save train checkpoints and predict results                   |
| `save_period`     | `-1`     | Save checkpoint every x epochs (disabled if < 1)             |
| `cache`           | `False`  | True/ram, disk or False. Use cache for data loading          |
| `device`          | `None`   | device to run on, i.e. cuda device=0 or device=0,1,2,3 or device=cpu |
| `workers`         | `8`      | number of worker threads for data loading (per RANK if DDP)  |
| `project`         | `None`   | project name                                                 |
| `name`            | `None`   | experiment name                                              |
| `exist_ok`        | `False`  | whether to overwrite existing experiment                     |
| `pretrained`      | `False`  | whether to use a pretrained model                            |
| `optimizer`       | `'SGD'`  | optimizer to use, choices=['SGD', 'Adam', 'AdamW', 'RMSProp'] |
| `verbose`         | `False`  | whether to print verbose output                              |
| `seed`            | `0`      | random seed for reproducibility                              |
| `deterministic`   | `True`   | whether to enable deterministic mode                         |
| `single_cls`      | `False`  | train multi-class data as single-class                       |
| `image_weights`   | `False`  | use weighted image selection for training                    |
| `rect`            | `False`  | support rectangular training                                 |
| `cos_lr`          | `False`  | use cosine learning rate scheduler                           |
| `close_mosaic`    | `10`     | disable mosaic augmentation for final 10 epochs              |
| `resume`          | `False`  | resume training from last checkpoint                         |
| `amp`             | `True`   | Automatic Mixed Precision (AMP) training, choices=[True, False] |
| `lr0`             | `0.01`   | initial learning rate (i.e. SGD=1E-2, Adam=1E-3)             |
| `lrf`             | `0.01`   | final learning rate (lr0 * lrf)                              |
| `momentum`        | `0.937`  | SGD momentum/Adam beta1                                      |
| `weight_decay`    | `0.0005` | optimizer weight decay 5e-4                                  |
| `warmup_epochs`   | `3.0`    | warmup epochs (fractions ok)                                 |
| `warmup_momentum` | `0.8`    | warmup initial momentum                                      |
| `warmup_bias_lr`  | `0.1`    | warmup initial bias lr                                       |
| `box`             | `7.5`    | box loss gain                                                |
| `cls`             | `0.5`    | cls loss gain (scale with pixels)                            |
| `dfl`             | `1.5`    | dfl loss gain                                                |
| `fl_gamma`        | `0.0`    | focal loss gamma (efficientDet default gamma=1.5)            |
| `label_smoothing` | `0.0`    | label smoothing (fraction)                                   |
| `nbs`             | `64`     | nominal batch size                                           |
| `overlap_mask`    | `True`   | masks should overlap during training (segment train only)    |
| `mask_ratio`      | `4`      | mask downsample ratio (segment train only)                   |
| `dropout`         | `0.0`    | use dropout regularization (classify train only)             |
| `val`             | `True`   | validate/test during training                                |

> `SGD`

```sh
yolo task=detect mode=train imgsz=640 batch=-1 epochs=300 optimizer=SGD lr0=0.01 cos_lr=True device=0 pretrained=True model=ultralytics/models/v8/yolov8n.yaml data=ultralytics/datasets/coco128.yaml
yolo task=detect mode=train imgsz=640 batch=-1 epochs=300 optimizer=SGD lr0=0.01 cos_lr=True device=0 pretrained=True model=ultralytics/models/v8/yolov8s.yaml data=ultralytics/datasets/coco128.yaml
yolo task=detect mode=train imgsz=640 batch=-1 epochs=300 optimizer=SGD lr0=0.01 cos_lr=True device=0 pretrained=True model=ultralytics/models/v8/yolov8m.yaml data=ultralytics/datasets/coco128.yaml
yolo task=detect mode=train imgsz=640 batch=-1 epochs=300 optimizer=SGD lr0=0.01 cos_lr=True device=0 pretrained=True model=ultralytics/models/v8/yolov8l.yaml data=ultralytics/datasets/coco128.yaml
yolo task=detect mode=train imgsz=640 batch=-1 epochs=300 optimizer=SGD lr0=0.01 cos_lr=True device=0 pretrained=True model=ultralytics/models/v8/yolov8x.yaml data=ultralytics/datasets/coco128.yaml
```

> `Adam`

```sh
yolo task=detect mode=train imgsz=640 batch=-1 epochs=300 optimizer=AdamW lr0=0.001 cos_lr=True device=0 pretrained=True model=ultralytics/models/v8/yolov8n.yaml data=ultralytics/datasets/coco128.yaml
yolo task=detect mode=train imgsz=640 batch=-1 epochs=300 optimizer=AdamW lr0=0.001 cos_lr=True device=0 pretrained=True model=ultralytics/models/v8/yolov8s.yaml data=ultralytics/datasets/coco128.yaml
yolo task=detect mode=train imgsz=640 batch=-1 epochs=300 optimizer=AdamW lr0=0.001 cos_lr=True device=0 pretrained=True model=ultralytics/models/v8/yolov8m.yaml data=ultralytics/datasets/coco128.yaml
yolo task=detect mode=train imgsz=640 batch=-1 epochs=300 optimizer=AdamW lr0=0.001 cos_lr=True device=0 pretrained=True model=ultralytics/models/v8/yolov8l.yaml data=ultralytics/datasets/coco128.yaml
yolo task=detect mode=train imgsz=640 batch=-1 epochs=300 optimizer=AdamW lr0=0.001 cos_lr=True device=0 pretrained=True model=ultralytics/models/v8/yolov8x.yaml data=ultralytics/datasets/coco128.yaml
```



# export

Export settings for YOLO models refer to the various configurations and options used to save or export the model for use in other environments or platforms. These settings can affect the model's performance, size, and compatibility with different systems. Some common YOLO export settings include the format of the exported model file (e.g. ONNX, TensorFlow SavedModel), the device on which the model will be run (e.g. CPU, GPU), and the presence of additional features such as masks or multiple labels per box. Other factors that may affect the export process include the specific task the model is being used for and the requirements or constraints of the target environment or platform. It is important to carefully consider and configure these settings to ensure that the exported model is optimized for the intended use case and can be used effectively in the target environment.

| Key         | Value           | Description                                          |
| :---------- | :-------------- | :--------------------------------------------------- |
| `format`    | `'torchscript'` | format to export to                                  |
| `imgsz`     | `640`           | image size as scalar or (h, w) list, i.e. (640, 480) |
| `keras`     | `False`         | use Keras for TF SavedModel export                   |
| `optimize`  | `False`         | TorchScript: optimize for mobile                     |
| `half`      | `False`         | FP16 quantization                                    |
| `int8`      | `False`         | INT8 quantization                                    |
| `dynamic`   | `False`         | ONNX/TF/TensorRT: dynamic axes                       |
| `simplify`  | `False`         | ONNX: simplify model                                 |
| `opset`     | `None`          | ONNX: opset version (optional, defaults to latest)   |
| `workspace` | `4`             | TensorRT: workspace size (GB)                        |
| `nms`       | `False`         | CoreML: add NMS                                      |

| Format                                                       | `format=`     | Model                     |
| :----------------------------------------------------------- | :------------ | :------------------------ |
| [PyTorch](https://pytorch.org/)                              | -             | `yolov8n.pt`              |
| [TorchScript](https://pytorch.org/docs/stable/jit.html)      | `torchscript` | `yolov8n.torchscript`     |
| [ONNX](https://onnx.ai/)                                     | `onnx`        | `yolov8n.onnx`            |
| [OpenVINO](https://docs.openvino.ai/latest/index.html)       | `openvino`    | `yolov8n_openvino_model/` |
| [TensorRT](https://developer.nvidia.com/tensorrt)            | `engine`      | `yolov8n.engine`          |
| [CoreML](https://github.com/apple/coremltools)               | `coreml`      | `yolov8n.mlmodel`         |
| [TensorFlow SavedModel](https://www.tensorflow.org/guide/saved_model) | `saved_model` | `yolov8n_saved_model/`    |
| [TensorFlow GraphDef](https://www.tensorflow.org/api_docs/python/tf/Graph) | `pb`          | `yolov8n.pb`              |
| [TensorFlow Lite](https://www.tensorflow.org/lite)           | `tflite`      | `yolov8n.tflite`          |
| [TensorFlow Edge TPU](https://coral.ai/docs/edgetpu/models-intro/) | `edgetpu`     | `yolov8n_edgetpu.tflite`  |
| [TensorFlow.js](https://www.tensorflow.org/js)               | `tfjs`        | `yolov8n_web_model/`      |
| [PaddlePaddle](https://github.com/PaddlePaddle)              | `paddle`      | `yolov8n_paddle_model/`   |

## torchscript

```sh
yolo task=detect mode=export imgsz=640 model=weights/yolov8s.pt format=torchscript optimize=True device=0
```

## onnx

> æ³¨æ„:
>
> `onnxruntime` å’Œ `onnxruntime-gpu` ä¸è¦åŒæ—¶å®‰è£…ï¼Œå¦åˆ™ä½¿ç”¨ `gpu` æ¨ç†æ—¶é€Ÿåº¦ä¼šå¾ˆæ…¢ï¼Œå¦‚æœåŒæ—¶å®‰è£…äº†2ä¸ªåŒ…ï¼Œè¦å…¨éƒ¨å¸è½½ï¼Œå†å®‰è£…`onnxruntime-gpu` æ‰èƒ½ä½¿ç”¨gpuæ¨ç†ï¼Œå¦åˆ™gpué€Ÿåº¦ä¼šå¾ˆæ…¢

```sh
yolo task=detect mode=export imgsz=640 model=weights/yolov8s.pt format=onnx simplify=True
```

## openvino

```sh
yolo task=detect mode=export imgsz=640 model=weights/yolov8s.pt format=openvino
```

### é€šè¿‡openvinoçš„`mo`å‘½ä»¤å°†onnxè½¬æ¢ä¸ºopenvinoæ ¼å¼(æ”¯æŒ**fp16**)

> https://docs.openvino.ai/latest/notebooks/102-pytorch-onnx-to-openvino-with-output.html

```sh
mo --input_model "onnx_path" --output_dir "output_path" --compress_to_fp16

mo --input_model "onnx_path" --output_dir "output_path" --compress_to_fp16
```

#### ä»£ç æ–¹å¼

```python
from openvino.tools import mo
from openvino.runtime import serialize

onnx_path = "onnx_path"

# fp32 IR model
fp32_path = "fp32_path"
output_path = fp32_path + ".xml"
print(f"Export ONNX to OpenVINO FP32 IR to: {output_path}")
model = mo.convert_model(onnx_path)
serialize(model, output_path)

# fp16 IR model
fp16_path = "fp16_path"
output_path = fp16_path + ".xml"

print(f"Export ONNX to OpenVINO FP16 IR to: {output_path}")
model = mo.convert_model(onnx_path, compress_to_fp16=True)
serialize(model, output_path)
```

### export failure  0.9s: DLL load failed while importing ie_api

> https://blog.csdn.net/qq_26815239/article/details/123047840
>
> å¦‚æœä½ ä½¿ç”¨çš„æ˜¯ Python 3.8 æˆ–æ›´é«˜ç‰ˆæœ¬ï¼Œå¹¶ä¸”æ˜¯åœ¨Windowsç³»ç»Ÿä¸‹é€šè¿‡pipå®‰è£…çš„openvinoï¼Œé‚£ä¹ˆè¯¥é”™è¯¯çš„è§£å†³æ–¹æ¡ˆå¦‚ä¸‹ï¼š

1. è¿›å…¥ç›®å½• `your\env\site-packages\openvino\inference_engine`
2. æ‰“å¼€æ–‡ä»¶ `__init__.py`
3. 26è¡Œä¸‹æ·»åŠ ä¸€è¡Œ

```python
        if os.path.isdir(lib_path):
            # On Windows, with Python >= 3.8, DLLs are no longer imported from the PATH.
            if (3, 8) <= sys.version_info:
                os.add_dll_directory(os.path.abspath(lib_path))
                os.environ['PATH'] = os.path.abspath(lib_path) + ';' + os.environ['PATH']	# æ·»åŠ è¿™ä¸€è¡Œ
```

## tensorrt

```sh
yolo task=detect mode=export imgsz=640 model=weights/yolov8s.pt format=engine half=True device=0
```

## onnx openvino tensorrt

```sh
yolo task=detect mode=export imgsz=640 model=weights/yolov8s.pt format=onnx,openvino,engine simplify=True device=0 half=True
```

# detect

Prediction settings for YOLO models refer to the various hyperparameters and configurations used to make predictions with the model on new data. These settings can affect the model's performance, speed, and accuracy. Some common YOLO prediction settings include the confidence threshold, non-maximum suppression (NMS) threshold, and the number of classes to consider. Other factors that may affect the prediction process include the size and format of the input data, the presence of additional features such as masks or multiple labels per box, and the specific task the model is being used for. It is important to carefully tune and experiment with these settings to achieve the best possible performance for a given task.

| Key              | Value                  | Description                                              |
| :--------------- | :--------------------- | :------------------------------------------------------- |
| `source`         | `'ultralytics/assets'` | source directory for images or videos                    |
| `conf`           | `0.25`                 | object confidence threshold for detection                |
| `iou`            | `0.7`                  | intersection over union (IoU) threshold for NMS          |
| `half`           | `False`                | use half precision (FP16)                                |
| `device`         | `None`                 | device to run on, i.e. cuda device=0/1/2/3 or device=cpu |
| `show`           | `False`                | show results if possible                                 |
| `save`           | `False`                | save images with results                                 |
| `save_txt`       | `False`                | save results as .txt file                                |
| `save_conf`      | `False`                | save results with confidence scores                      |
| `save_crop`      | `False`                | save cropped images with results                         |
| `hide_labels`    | `False`                | hide labels                                              |
| `hide_conf`      | `False`                | hide confidence scores                                   |
| `max_det`        | `300`                  | maximum number of detections per image                   |
| `vid_stride`     | `False`                | video frame-rate stride                                  |
| `line_thickness` | `3`                    | bounding box thickness (pixels)                          |
| `visualize`      | `False`                | visualize model features                                 |
| `augment`        | `False`                | apply image augmentation to prediction sources           |
| `agnostic_nms`   | `False`                | class-agnostic NMS                                       |
| `retina_masks`   | `False`                | use high-resolution segmentation masks                   |
| `classes`        | `None`                 | filter results by class, i.e. class=0, or class=[0,2,3]  |
| `boxes`          | `True`                 | Show boxes in segmentation predictions                   |

## torch

```sh
yolo task=detect mode=detect imgsz=640 save=True model=weights/yolov8n.pt source=data/images/bus.jpg device=0

yolo task=detect mode=detect imgsz=640 save=True model=weights/yolov8n.pt source=../datasets/coco128/images/train2017 device=0
```

## torchscript

```sh
yolo task=detect mode=detect imgsz=640 save=True model=weights/yolov8s.torchscript source=data/images/bus.jpg device=0

yolo task=detect mode=detect imgsz=640 save=True model=weights/yolov8s.torchscript source=../datasets/coco128/images/train2017 device=0
```

## onnx

> æ³¨æ„:
>
> `onnxruntime` å’Œ `onnxruntime-gpu` ä¸è¦åŒæ—¶å®‰è£…ï¼Œå¦åˆ™ä½¿ç”¨ `gpu` æ¨ç†æ—¶é€Ÿåº¦ä¼šå¾ˆæ…¢ï¼Œå¦‚æœåŒæ—¶å®‰è£…äº†2ä¸ªåŒ…ï¼Œè¦å…¨éƒ¨å¸è½½ï¼Œå†å®‰è£… `onnxruntime-gpu` æ‰èƒ½ä½¿ç”¨gpuæ¨ç†ï¼Œå¦åˆ™gpué€Ÿåº¦ä¼šå¾ˆæ…¢

```sh
yolo task=detect mode=detect imgsz=640 save=True model=weights/yolov8s.onnx source=data/images/bus.jpg device=0

yolo task=detect mode=detect imgsz=640 save=True model=weights/yolov8s.onnx source=../datasets/coco128/images/train2017 device=0
```

## openvino

> æ³¨æ„ï¼šopenvinoæ²¡æ³•ä½¿ç”¨cudaï¼Œä½†æ˜¯ä½¿ç”¨ --device 0 ä¼šæé«˜æ¨ç†é€Ÿåº¦

```sh
yolo task=detect mode=detect imgsz=640 save=True model=weights/yolov8s_openvino_model source=data/images/bus.jpg device=cpu

yolo task=detect mode=detect imgsz=640 save=True model=weights/yolov8s_openvino_model source=../datasets/coco128/images/train2017 device=cpu
```

## tensorrt

```sh
yolo task=detect mode=detect imgsz=640 save=True model=weights/yolov8s.engine source=data/images/bus.jpg device=0

yolo task=detect mode=detect imgsz=640 save=True model=weights/yolov8s.engine source=../datasets/coco128/images/train2017 device=0
```

# val

Validation settings for YOLO models refer to the various hyperparameters and configurations used to evaluate the model's performance on a validation dataset. These settings can affect the model's performance, speed, and accuracy. Some common YOLO validation settings include the batch size, the frequency with which validation is performed during training, and the metrics used to evaluate the model's performance. Other factors that may affect the validation process include the size and composition of the validation dataset and the specific task the model is being used for. It is important to carefully tune and experiment with these settings to ensure that the model is performing well on the validation dataset and to detect and prevent overfitting.

| Key           | Value   | Description                                                  |
| :------------ | :------ | :----------------------------------------------------------- |
| `save_json`   | `False` | save results to JSON file                                    |
| `save_hybrid` | `False` | save hybrid version of labels (labels + additional predictions) |
| `conf`        | `0.001` | object confidence threshold for detection                    |
| `iou`         | `0.6`   | intersection over union (IoU) threshold for NMS              |
| `max_det`     | `300`   | maximum number of detections per image                       |
| `half`        | `True`  | use half precision (FP16)                                    |
| `device`      | `None`  | device to run on, i.e. cuda device=0/1/2/3 or device=cpu     |
| `dnn`         | `False` | use OpenCV DNN for ONNX inference                            |
| `plots`       | `False` | show plots during training                                   |
| `rect`        | `False` | support rectangular evaluation                               |
| `split`       | `val`   | dataset split to use for validation, i.e. 'val', 'test' or 'train' |

## torch

```sh
yolo task=detect mode=val imgsz=640 model=weights/yolov8s.pt save_json=True save_hybrid=True save_txt=True save_conf=True device=0
```

## torchscript

```sh
yolo task=detect mode=val imgsz=640 model=weights/yolov8s.torchscript save_json=True save_hybrid=True save_txt=True save_conf=True device=0
```

## onnx

> æ³¨æ„:
>
> `onnxruntime` å’Œ `onnxruntime-gpu` ä¸è¦åŒæ—¶å®‰è£…ï¼Œå¦åˆ™ä½¿ç”¨ `gpu` æ¨ç†æ—¶é€Ÿåº¦ä¼šå¾ˆæ…¢ï¼Œå¦‚æœåŒæ—¶å®‰è£…äº†2ä¸ªåŒ…ï¼Œè¦å…¨éƒ¨å¸è½½ï¼Œå†å®‰è£… `onnxruntime-gpu` æ‰èƒ½ä½¿ç”¨gpuæ¨ç†ï¼Œå¦åˆ™gpué€Ÿåº¦ä¼šå¾ˆæ…¢

```sh
yolo task=detect mode=val imgsz=640 model=weights/yolov8s.onnx save_json=True save_hybrid=True save_txt=True save_conf=True device=0
```

## openvino

> æ³¨æ„ï¼šopenvinoæ²¡æ³•ä½¿ç”¨cudaï¼Œä½†æ˜¯ä½¿ç”¨ --device 0 ä¼šæé«˜æ¨ç†é€Ÿåº¦

```sh
yolo task=detect mode=val imgsz=640 model=weights/yolov8s_openvnio_model save_json=True save_hybrid=True save_txt=True save_conf=True device=cpu
```

## tensorrt

```sh
yolo task=detect mode=val imgsz=640 model=weights/yolov8s.onnx save_json=True save_hybrid=True device=0 save_txt=True save_conf=True half=True
```

